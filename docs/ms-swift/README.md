# ms-swiftè¿˜æä¾›äº†åŸºäºGradioçš„Web-UIç•Œé¢åŠä¸°å¯Œçš„æœ€ä½³å®è·µã€‚
ğŸ æ¨¡å‹ç±»å‹ï¼šæ”¯æŒ500+çº¯æ–‡æœ¬å¤§æ¨¡å‹ã€200+å¤šæ¨¡æ€å¤§æ¨¡å‹ä»¥åŠAll-to-Allå…¨æ¨¡æ€æ¨¡å‹ã€åºåˆ—åˆ†ç±»æ¨¡å‹ã€Embeddingæ¨¡å‹è®­ç»ƒåˆ°éƒ¨ç½²å…¨æµç¨‹ã€‚
æ•°æ®é›†ç±»å‹ï¼šå†…ç½®150+é¢„è®­ç»ƒã€å¾®è°ƒã€äººç±»å¯¹é½ã€å¤šæ¨¡æ€ç­‰å„ç§ç±»å‹çš„æ•°æ®é›†ï¼Œå¹¶æ”¯æŒè‡ªå®šä¹‰æ•°æ®é›†ã€‚
ç¡¬ä»¶æ”¯æŒï¼šCPUã€RTXç³»åˆ—ã€T4/V100ã€A10/A100/H100ã€Ascend NPUã€MPSç­‰ã€‚
è½»é‡è®­ç»ƒï¼šæ”¯æŒäº†LoRAã€QLoRAã€DoRAã€LoRA+ã€ReFTã€RS-LoRAã€LLaMAProã€Adapterã€GaLoreã€Q-Galoreã€LISAã€UnSlothã€Liger-Kernelç­‰è½»é‡å¾®è°ƒæ–¹å¼ã€‚
åˆ†å¸ƒå¼è®­ç»ƒï¼šæ”¯æŒåˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œï¼ˆDDPï¼‰ã€device_mapç®€æ˜“æ¨¡å‹å¹¶è¡Œã€DeepSpeed ZeRO2 ZeRO3ã€FSDPã€Megatronç­‰åˆ†å¸ƒå¼è®­ç»ƒæŠ€æœ¯ã€‚
é‡åŒ–è®­ç»ƒï¼šæ”¯æŒå¯¹BNBã€AWQã€GPTQã€AQLMã€HQQã€EETQé‡åŒ–æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚
ğŸŠ RLHFè®­ç»ƒï¼šæ”¯æŒçº¯æ–‡æœ¬å¤§æ¨¡å‹å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹çš„DPOã€GRPOã€RMã€PPOã€GKDã€KTOã€CPOã€SimPOã€ORPOç­‰äººç±»å¯¹é½è®­ç»ƒæ–¹æ³•ã€‚
ğŸ“ å¤šæ¨¡æ€è®­ç»ƒï¼šæ”¯æŒå¯¹å›¾åƒã€è§†é¢‘å’Œè¯­éŸ³ä¸åŒæ¨¡æ€æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œæ”¯æŒVQAã€Captionã€OCRã€Groundingä»»åŠ¡çš„è®­ç»ƒã€‚
ğŸ¥¥ Megatronå¹¶è¡ŒæŠ€æœ¯ï¼šæ”¯æŒä½¿ç”¨Megatronå¹¶è¡ŒæŠ€æœ¯å¯¹CPT/SFT/DPOè¿›è¡ŒåŠ é€Ÿï¼Œç°æ”¯æŒ200+å¤§è¯­è¨€æ¨¡å‹ã€‚
ç•Œé¢è®­ç»ƒï¼šä»¥ç•Œé¢çš„æ–¹å¼æä¾›è®­ç»ƒã€æ¨ç†ã€è¯„æµ‹ã€é‡åŒ–çš„èƒ½åŠ›ï¼Œå®Œæˆå¤§æ¨¡å‹çš„å…¨é“¾è·¯ã€‚
æ’ä»¶åŒ–ä¸æ‹“å±•ï¼šæ”¯æŒè‡ªå®šä¹‰æ¨¡å‹å’Œæ•°æ®é›†æ‹“å±•ï¼Œæ”¯æŒå¯¹lossã€metricã€trainerã€loss-scaleã€callbackã€optimizerç­‰ç»„ä»¶è¿›è¡Œè‡ªå®šä¹‰ã€‚
ğŸ‰ å·¥å…·ç®±èƒ½åŠ›ï¼šä¸ä»…æä¾›å¤§æ¨¡å‹å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹çš„è®­ç»ƒæ”¯æŒï¼Œè¿˜æ¶µç›–å…¶æ¨ç†ã€è¯„æµ‹ã€é‡åŒ–å’Œéƒ¨ç½²å…¨æµç¨‹ã€‚
æ¨ç†åŠ é€Ÿï¼šæ”¯æŒPyTorchã€vLLMã€SGLangå’ŒLmDeployæ¨ç†åŠ é€Ÿå¼•æ“ï¼Œå¹¶æä¾›OpenAIæ¥å£ï¼Œä¸ºæ¨ç†ã€éƒ¨ç½²å’Œè¯„æµ‹æ¨¡å—æä¾›åŠ é€Ÿã€‚
æ¨¡å‹è¯„æµ‹ï¼šä»¥EvalScopeä½œä¸ºè¯„æµ‹åç«¯ï¼Œæ”¯æŒ100+è¯„æµ‹æ•°æ®é›†å¯¹çº¯æ–‡æœ¬å’Œå¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œè¯„æµ‹ã€‚
æ¨¡å‹é‡åŒ–ï¼šæ”¯æŒAWQã€GPTQã€FP8å’ŒBNBçš„é‡åŒ–å¯¼å‡ºï¼Œå¯¼å‡ºçš„æ¨¡å‹æ”¯æŒä½¿ç”¨vLLM/SGLang/LmDeployæ¨ç†åŠ é€Ÿï¼Œå¹¶æ”¯æŒç»§ç»­è®­ç»ƒã€‚


# éƒ¨ç½²
https://swift.readthedocs.io/zh-cn/latest/GetStarted/SWIFT%E5%AE%89%E8%A3%85.html#id3
modelscope-registry.cn-beijing.cr.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda12.6.3-py311-torch2.7.1-vllm0.10.1.1-modelscope1.29.2-swift3.8.1

# ç¯å¢ƒéƒ¨ç½²

##  å°è¯•ä½¿ç”¨verlçš„é•œåƒ
```
# è·å–é•œåƒ
docker pull modelscope-registry.cn-beijing.cr.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda12.6.3-py311-torch2.7.1-vllm0.10.1.1-modelscope1.29.2-swift3.8.1
# ä½¿ç”¨å“ªä¸ªGPU, å¯ä»¥ä¸ºallï¼Œæˆ–è€…æŸä¸ªæ˜¾å¡
docker create --runtime=nvidia --gpus "device=2" --net=host --shm-size="10g" --cap-add=SYS_ADMIN -v .:/workspace/verl -v /etc/localtime:/etc/localtime:ro -v /etc/timezone:/etc/timezone:ro --name swift modelscope-registry.cn-beijing.cr.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda12.6.3-py311-torch2.7.1-vllm0.10.1.1-modelscope1.29.2-swift3.8.1 sleep infinity
# å¯åŠ¨å®¹å™¨
docker start swift
docker exec -it swift bash
```

## ~/.bashrcä¸­é…ç½®ä½¿ç”¨çš„GPUå’Œå®ç”¨çš„hugging faceé•œåƒ
export CUDA_VISIBLE_DEVICES=1
export HF_ENDPOINT=https://hf-mirror.com

## è®¾ç½®pipé•œåƒæº
```
pip config set global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
```
# å…‹éš†å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¡†æ¶
```
cd verl-agent
pip install .
```

## è®¾ç½®ä»£ç†ï¼Œå®‰è£…gitä¸Šçš„é¡¹ç›®
```
export http_proxy=http://127.0.0.1:7890
export https_proxy=http://127.0.0.1:7890
export all_proxy=http://127.0.0.1:7890
export HTTP_PROXY=http://127.0.0.1:7890
export HTTPs_PROXY=http://127.0.0.1:7890
pip install 'torchtune @ git+https://github.com/pytorch/torchtune.git'
pip install 'unsloth-zoo @ git+https://github.com/bradhilton/unsloth-zoo'
```

## WanDB docker è®­ç»ƒè®°å½•
```
docker pull wandb/local
docker run -d --restart always -v wandb:/vol -p 3005:8080 --name wandb-local wandb/local
#ä¼šæç¤ºæ‚¨é…ç½®æ‰“å¼€æµè§ˆå™¨http://localhost:3005/authorizeï¼Œæ–°å»ºä¸€ä¸ªæœ¬åœ°æ™®é€šç”¨æˆ·, ç²˜è´´key
è¾“å…¥é‚®ç®±å’Œç”¨æˆ·ååˆ›å»ºä¸€ä¸ªæœ¬åœ°çš„ç”¨æˆ·ï¼Œå¾—åˆ°ç±»ä¼¼è¿™æ ·çš„KEYï¼Œ local-f2ca8cd44276ac92ca0a2c12641a6902beb6847d
ç²˜è´´åˆ°.envçš„ç¯å¢ƒå˜é‡é…ç½®æ–‡ä»¶ä¸­
```


## SFTè®­ç»ƒ
swift sft \
    --model Qwen/Qwen2.5-7B-Instruct \
    --train_type lora \
    --dataset 'AI-ModelScope/alpaca-gpt4-data-zh#500' \
              'AI-ModelScope/alpaca-gpt4-data-en#500' \
              'swift/self-cognition#500' \
    --torch_dtype bfloat16 \
    --num_train_epochs 1 \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --learning_rate 1e-4 \
    --lora_rank 8 \
    --lora_alpha 32 \
    --target_modules all-linear \
    --gradient_accumulation_steps 16 \
    --eval_steps 50 \
    --save_steps 50 \
    --save_total_limit 2 \
    --logging_steps 5 \
    --max_length 2048 \
    --output_dir output \
    --system 'You are a helpful assistant.' \
    --warmup_ratio 0.05 \
    --dataloader_num_workers 4 \
    --model_author swift \
    --model_name swift-robot

## SFTæ¨ç†ï¼Œ æ¨ç†æ…¢ï¼Œä½†æ˜¯åŠ è½½é€Ÿåº¦å¿«
swift infer \
    --adapters ./output/v0-20250926-114832/checkpoint-94 \
    --stream true \
    --temperature 0 \
    --max_new_tokens 2048
```
[INFO:swift] Input `exit` or `quit` to exit the conversation.
[INFO:swift] Input `multi-line` to switch to multi-line input mode.
[INFO:swift] Input `reset-system` to reset the system and clear the history.
[INFO:swift] Input `clear` to clear the history.
<<<
<<<
<<< ä½ æ˜¯è°
æˆ‘æ˜¯swift-robotï¼Œç”±swiftå¼€å‘çš„äººå·¥æ™ºèƒ½èŠå¤©æœºå™¨äººã€‚æˆ‘è¢«è®¾è®¡ç”¨æ¥ç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œä»¥ä¾¿ä¸äººç±»è¿›è¡Œäº¤æµå’Œå¯¹è¯ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼
--------------------------------------------------
```

## åˆå¹¶loraçš„æƒé‡ï¼Œç„¶åä½¿ç”¨vllmæ¨ç†ï¼Œ æ¨ç†é€Ÿåº¦æ›´å¿«ï¼Œä½†æ˜¯åŠ è½½æ—¶æ…¢ï¼Œè¿è¡Œç»“æŸåä¼šç”Ÿæˆmergedçš„æ¨¡å‹æƒé‡
ä¾‹å¦‚ï¼šoutput/v0-20250926-114832/checkpoint-94-merged/
swift infer \
    --adapters ./output/v0-20250926-114832/checkpoint-94 \
    --stream true \
    --merge_lora true \
    --infer_backend vllm \
    --vllm_max_model_len 8192 \
    --temperature 0 \
    --max_new_tokens 2048


## å¯åŠ¨WebUI,ç„¶åä½¿ç”¨è®¿é—®: http://xxxx:7860/
swift web-ui --lang zh

## æµ‹è¯•çš„WebUI, ç„¶åä½¿ç”¨è®¿é—®: http://xxxx:7860/
swift app --model Qwen/Qwen2.5-7B-Instruct --adapters ./output/v0-20250926-114832/checkpoint-94 --stream true

# éƒ¨ç½²ï¼ˆå¾®è°ƒåæ¨¡å‹ï¼‰ïƒ
ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨éƒ¨ç½²æœåŠ¡ç«¯ã€‚å¦‚æœæƒé‡ä½¿ç”¨å…¨å‚æ•°è®­ç»ƒï¼Œè¯·ä½¿ç”¨--modelæ›¿ä»£--adaptersæŒ‡å®šè®­ç»ƒçš„checkpointç›®å½•ã€‚ä½ å¯ä»¥å‚è€ƒæ¨ç†å’Œéƒ¨ç½²æ–‡æ¡£ä»‹ç»çš„å®¢æˆ·ç«¯è°ƒç”¨æ–¹å¼ï¼šcurlã€openaiåº“å’Œswiftå®¢æˆ·ç«¯è¿›è¡Œè°ƒç”¨ã€‚

swift deploy \
    --adapters ./output/v0-20250926-114832/checkpoint-94 \
    --infer_backend pt \
    --temperature 0 \
    --max_new_tokens 2048 \
    --served_model_name 'mylora-model'
è¿™é‡Œå°†ç»™å‡ºä½¿ç”¨vLLMå¯¹å¤šLoRAè¿›è¡Œéƒ¨ç½²å¹¶è°ƒç”¨çš„å®Œæ•´ä¾‹å­ã€‚

vllmçš„æœåŠ¡ç«¯ïƒ
é¦–å…ˆä½ éœ€è¦å®‰è£…vLLMï¼špip install vllm -Uï¼Œå¹¶åœ¨éƒ¨ç½²æ—¶ä½¿ç”¨--infer_backend vllmï¼Œè¿™é€šå¸¸å¯ä»¥æ˜¾è‘—åŠ é€Ÿæ¨ç†é€Ÿåº¦ã€‚

æˆ‘ä»¬é¢„å…ˆè®­ç»ƒäº†2ä¸ªåŸºæ¨¡å‹ä¸ºQwen/Qwen2.5-7B-Instructçš„ä¸åŒè‡ªæˆ‘è®¤çŸ¥LoRAå¢é‡æƒé‡ï¼ˆå¯ä»¥ç›´æ¥è·‘é€šï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨args.jsonä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚ä½ éœ€è¦åœ¨éƒ¨ç½²æ—¶ä¿®æ”¹--adaptersæŒ‡å®šè®­ç»ƒå¥½çš„LoRAæƒé‡æœ¬åœ°è·¯å¾„å³å¯ã€‚

swift deploy \
    --adapters lora1=swift/test_lora lora2=swift/test_lora2 \
    --infer_backend vllm \
    --temperature 0 \
    --max_new_tokens 2048

å®¢æˆ·ç«¯ïƒ
è¿™é‡Œåªä»‹ç»ä½¿ç”¨openaiåº“è¿›è¡Œè°ƒç”¨ã€‚ä½¿ç”¨curlã€swiftå®¢æˆ·ç«¯è°ƒç”¨çš„ä¾‹å­å¯ä»¥å‚è€ƒæ¨ç†å’Œéƒ¨ç½²æ–‡æ¡£ã€‚

```
from openai import OpenAI

client = OpenAI(
    api_key='EMPTY',
    base_url=f'http://127.0.0.1:8000/v1',
)
models = [model.id for model in client.models.list().data]
print(f'models: {models}')

query = 'who are you?'
messages = [{'role': 'user', 'content': query}]

resp = client.chat.completions.create(model=models[1], messages=messages, max_tokens=512, temperature=0)
query = messages[0]['content']
response = resp.choices[0].message.content
print(f'query: {query}')
print(f'response: {response}')

gen = client.chat.completions.create(model=models[2], messages=messages, stream=True, temperature=0)
print(f'query: {query}\nresponse: ', end='')
for chunk in gen:
    if chunk is None:
        continue
    print(chunk.choices[0].delta.content, end='', flush=True)
print()
"""
models: ['Qwen2.5-7B-Instruct', 'lora1', 'lora2']
query: who are you?
response: I am an artificial intelligence model named swift-robot, developed by swift. I can answer your questions, provide information, and engage in conversation. If you have any inquiries or need assistance, feel free to ask me at any time.
query: who are you?
response: I am an artificial intelligence model named Xiao Huang, developed by ModelScope. I can answer your questions, provide information, and engage in conversation. If you have any inquiries or need assistance, feel free to ask me at any time.
"""
```