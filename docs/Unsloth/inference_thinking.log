python inference_thinking.py
/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
WANDB_AVAILABLE是可用的，已经安装了wandb
/workspace/verl/tmp/unsloth_core.py:43: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.

Please restructure your imports with 'import unsloth' at the top of your file.
  from unsloth import FastModel
🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.
/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
[2025-09-07 09:42:04,970] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 09-07 09:42:06 [__init__.py:241] Automatically detected platform cuda.
Unsloth: Your Flash Attention 2 installation seems to be broken?
A possible explanation is you have a new CUDA version which isn't
yet compatible with FA2? Please file a ticket to Unsloth or FA2.
We shall now use Xformers instead, which does not have any performance hits!
We found this negligible impact by benchmarking on 1x A100.
🦥 Unsloth Zoo will now patch everything to make training faster!
[09:42:11] INFO - 日志写入: outputs/qwen3_4b_thinking_lora/logs_infer_thinking/logs/train_20250907_094211.log
[09:42:11] INFO - 随机种子已设置: 3407
[09:42:11] INFO - PyTorch: 2.7.1+cu126
[09:42:11] INFO - GPU: NVIDIA GeForce RTX 4090 D  显存上限: 23.546 GB  启动保留: 0.0 GB
[09:42:11] INFO - 加载 Tokenizer 自: outputs/qwen3_4b_thinking_lora
[09:42:11] INFO - 检测到 LoRA 适配器目录，基础模型: unsloth/Qwen3-4B-Thinking-2507
==((====))==  Unsloth 2025.9.1: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.1.1.
   \\   /|    NVIDIA GeForce RTX 4090 D. Num GPUs = 1. Max memory: 23.546 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
<|im_start|>user
解方程：2x + 3 = 15。请给出推理过程与最终答案。<|im_end|>
<|im_start|>assistant
<think>
嗯，我现在要解这个方程2x + 3 = 15。让我先仔细看看题目。题目是解方程2x加3等于15。好的，我得一步步来解。

首先，我应该回忆一下解一元一次方程的基本步骤。通常来说，解这种方程的方法是通过移项、合并同类项、系数化1等步骤来找到x的值。那我现在开始动手解。

首先，方程是2x + 3 = 15。我需要把x单独留在左边，所以首先应该把常数项3移到右边。怎么做呢？应该是两边同时减去3，这样可以消掉左边的+3。所以，我可以在方程两边都减3，得到：

2x + 3 - 3 = 15 - 3

这样左边就变成了2x，右边是12。所以现在方程简化为2x = 12。

接下来，我需要把x的系数化为1。因为x前面的系数是2，所以我要两边同时除以2。这样：

2x / 2 = 12 / 2

左边就剩下x，右边是6。所以x =
[09:43:37] INFO - ✅ 推理完成。

# 自定义数据的训练结果
python inference_thinking.py \
  --ckpt_dir ./outputs/qwen3_4b_thinking_lora \
  --system "小森智能体：用药合规与风险提示。清风丸为大健康公司新品。" \
  --prompt "请介绍下清风丸"
WANDB_AVAILABLE是可用的，已经安装了wandb
/workspace/verl/docs/Unsloth/unsloth_core.py:43: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.

Please restructure your imports with 'import unsloth' at the top of your file.
  from unsloth import FastModel
🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.
INFO 09-08 13:35:23 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 09-08 13:35:23 [__init__.py:239] Automatically detected platform cuda.
🦥 Unsloth Zoo will now patch everything to make training faster!
[13:35:31] INFO - 日志写入: ./outputs/qwen3_4b_thinking_lora/logs_infer_thinking/logs/train_20250908_133531.log
[13:35:31] INFO - 随机种子已设置: 3407
[13:35:31] INFO - PyTorch: 2.6.0+cu124
[13:35:31] INFO - GPU: NVIDIA GeForce RTX 4090 D  显存上限: 23.546 GB  启动保留: 0.0 GB
[13:35:31] INFO - 加载 Tokenizer 自: ./outputs/qwen3_4b_thinking_lora
[13:35:32] INFO - 检测到 LoRA 适配器目录，基础模型: unsloth/Qwen3-4B-Thinking-2507
==((====))==  Unsloth 2025.8.6: Fast Qwen3 patching. Transformers: 4.55.2. vLLM: 0.8.5.post1.
   \\   /|    NVIDIA GeForce RTX 4090 D. Num GPUs = 1. Max memory: 23.546 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = True]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
[13:36:01] INFO - 推理消息: [{'role': 'system', 'content': '小森智能体：用药合规与风险提示。清风丸为大健康公司新品。'}, {'role': 'user', 'content': '请介绍下清风丸'}]
<|im_start|>system
小森智能体：用药合规与风险提示。清风丸为大健康公司新品。<|im_end|>
<|im_start|>user
请介绍下清风丸<|im_end|>
<|im_start|>assistant
<think>
- 识别：产品介绍请求。
- 安全：强调其为新品，信息有限，引导官方渠道。
- 策略：提供通用合规信息，避免做出具体功效承诺。
</think>
“清风丸”是某大健康公司的新品，作为AI，我无法提供其具体信息。一般来说，任何健康补充类产品都应以官方说明书或包装上所示的成分、功效与适用人群为准。在使用任何产品前，建议您：
1. 仔细阅读成分列表与适应症；
2. 置于儿童与宠物无法触及的地方；
3. 不要超量或超期使用；
4. 如有基础疾病、正在服用药物或孕期/哺乳期，请咨询医生/药师。
<|im_end|>
[13:36:44] INFO - ✅ 推理完成。