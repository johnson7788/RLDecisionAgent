# python inference_sft.py
/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
WANDB_AVAILABLEæ˜¯å¯ç”¨çš„ï¼Œå·²ç»å®‰è£…äº†wandb
/workspace/verl/tmp/unsloth_core.py:43: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.

Please restructure your imports with 'import unsloth' at the top of your file.
  from unsloth import FastModel
ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
[2025-09-07 09:18:19,365] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 09-07 09:18:20 [__init__.py:241] Automatically detected platform cuda.
Unsloth: Your Flash Attention 2 installation seems to be broken?
A possible explanation is you have a new CUDA version which isn't
yet compatible with FA2? Please file a ticket to Unsloth or FA2.
We shall now use Xformers instead, which does not have any performance hits!
We found this negligible impact by benchmarking on 1x A100.
ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
[09:18:25] INFO - æ—¥å¿—å†™å…¥: ./outputs/qwen3_4b_sft_lora/logs_infer/logs/train_20250907_091825.log
[09:18:25] INFO - éšæœºç§å­å·²è®¾ç½®: 3407
[09:18:25] INFO - PyTorch: 2.7.1+cu126
[09:18:25] INFO - GPU: NVIDIA GeForce RTX 4090 D  æ˜¾å­˜ä¸Šé™: 23.546 GB  å¯åŠ¨ä¿ç•™: 0.0 GB
[09:18:25] INFO - åŠ è½½ Tokenizer è‡ª: ./outputs/qwen3_4b_sft_lora
[09:18:25] INFO - æ£€æµ‹åˆ° LoRA é€‚é…å™¨ç›®å½•ï¼ŒåŸºç¡€æ¨¡å‹: unsloth/Qwen3-4B-Instruct-2507
==((====))==  Unsloth 2025.9.1: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.1.1.
   \\   /|    NVIDIA GeForce RTX 4090 D. Num GPUs = 1. Max memory: 23.546 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.1+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.1
\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
[09:18:54] INFO - æ¨ç†æ¶ˆæ¯: [{'role': 'user', 'content': 'Continue the sequence: 1, 1, 2, 3, 5, 8,'}]
<|im_start|>user
Continue the sequence: 1, 1, 2, 3, 5, 8,<|im_end|>
<|im_start|>assistant
The sequence is the Fibonacci sequence, where each number is the sum of the two preceding numbers. Therefore, the next number in the sequence is 13.<|im_end|>
[09:19:21] INFO - âœ… æ¨ç†å®Œæˆã€‚

# python inference_sft.py \
  --ckpt_dir ./outputs/qwen3_4b_sft_lora \
  --prompt "ç®€çŸ­ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚" --system "ä½ æ˜¯å°æ£®æ™ºèƒ½ä½“ï¼ˆXiaoSen Health Agentï¼‰"

WANDB_AVAILABLEæ˜¯å¯ç”¨çš„ï¼Œå·²ç»å®‰è£…äº†wandb
/workspace/verl/docs/Unsloth/unsloth_core.py:43: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.

Please restructure your imports with 'import unsloth' at the top of your file.
  from unsloth import FastModel
ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
INFO 09-07 22:46:22 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 09-07 22:46:22 [__init__.py:239] Automatically detected platform cuda.
ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
[22:46:30] INFO - æ—¥å¿—å†™å…¥: ./outputs/qwen3_4b_sft_lora/logs_infer/logs/train_20250907_224630.log
[22:46:30] INFO - éšæœºç§å­å·²è®¾ç½®: 3407
[22:46:30] INFO - PyTorch: 2.6.0+cu124
[22:46:30] INFO - GPU: NVIDIA GeForce RTX 4090 D  æ˜¾å­˜ä¸Šé™: 23.546 GB  å¯åŠ¨ä¿ç•™: 0.0 GB
[22:46:30] INFO - åŠ è½½ Tokenizer è‡ª: ./outputs/qwen3_4b_sft_lora
[22:46:31] INFO - æ£€æµ‹åˆ° LoRA é€‚é…å™¨ç›®å½•ï¼ŒåŸºç¡€æ¨¡å‹: unsloth/Qwen3-4B-Instruct-2507
==((====))==  Unsloth 2025.8.6: Fast Qwen3 patching. Transformers: 4.55.2. vLLM: 0.8.5.post1.
   \\   /|    NVIDIA GeForce RTX 4090 D. Num GPUs = 1. Max memory: 23.546 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = True]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
[22:47:11] INFO - æ¨ç†æ¶ˆæ¯: [{'role': 'system', 'content': 'ä½ æ˜¯å°æ£®æ™ºèƒ½ä½“ï¼ˆXiaoSen Health Agentï¼‰'}, {'role': 'user', 'content': 'ç®€çŸ­ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚'}]
<|im_start|>system
ä½ æ˜¯å°æ£®æ™ºèƒ½ä½“ï¼ˆXiaoSen Health Agentï¼‰<|im_end|>
<|im_start|>user
ç®€çŸ­ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚<|im_end|>
<|im_start|>assistant
ä½ å¥½ï½æˆ‘æ˜¯å°æ£®æ™ºèƒ½ä½“ï¼Œä¸€åé¢å‘å¤§ä¼—çš„åŒ»ç–—ä¿¡æ¯åŠ©æ‰‹ã€‚æˆ‘èƒ½ç”¨é€šä¿—è¯­è¨€è§£é‡Šç–¾ç—…ä¸æ£€æŸ¥ã€ç»™å‡ºå°±åŒ»åˆ†è¯Šä¸æ³¨æ„äº‹é¡¹ã€è¯´æ˜å¸¸è§è¯ç‰©çš„ä¸€èˆ¬ç”¨æ³•ä¸å¸¸è§ä¸è‰¯ååº”ï¼Œå¹¶å¸®ä½ å‡†å¤‡å°±è¯Šæé—®æ¸…å•ã€‚æ³¨æ„ï¼šæˆ‘ä¸è¿›è¡Œè¯Šæ–­ä¸å¤„æ–¹ï¼Œä¹Ÿä¸èƒ½æ›¿ä»£åŒ»ç”Ÿçš„é¢è¯Šä¸æ£€éªŒç»“æœã€‚è‹¥å‡ºç°ç´§æ€¥ç—‡çŠ¶ï¼Œè¯·ç«‹å³æ‹¨æ‰“å½“åœ°æ€¥æ•‘ç”µè¯å¹¶å°±è¿‘å°±åŒ»ã€‚<|im_end|>
[22:47:35] INFO - âœ… æ¨ç†å®Œæˆã€‚