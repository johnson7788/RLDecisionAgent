# Parquet
Parquet æ˜¯ä¸€ç§åˆ—å¼å­˜å‚¨æ ¼å¼ï¼ˆColumnar Storage Formatï¼‰ï¼Œä¸“ä¸ºé«˜æ•ˆå­˜å‚¨å’Œå¤„ç†å¤§è§„æ¨¡æ•°æ®è€Œè®¾è®¡ï¼Œç‰¹åˆ«é€‚åˆå¤§æ•°æ®å¤„ç†å’Œåˆ†æåœºæ™¯ã€‚å®ƒæ˜¯ Apache å¼€å‘çš„å¼€æºé¡¹ç›®ï¼Œå¸¸ç”¨äº Hadoopã€Sparkã€Hiveã€Prestoã€Pandas ç­‰æ•°æ®å¤„ç†ç³»ç»Ÿä¸­ã€‚
```python
import pandas as pd

# ä¿å­˜ DataFrame ä¸º Parquet
df = pd.DataFrame({'a': [1, 2], 'b': ['x', 'y']})
df.to_parquet('train.parquet', engine='pyarrow')

# è¯»å– Parquet æ–‡ä»¶
df2 = pd.read_parquet('train.parquet', engine='pyarrow')
print(df2)
```

# è®­ç»ƒå‘½ä»¤è§£æ
PYTHONUNBUFFERED=1 python3 -m verl.trainer.main_ppo ...
PYTHONUNBUFFERED=1ï¼šè¾“å‡ºä¸ç¼“å†²ï¼Œç¡®ä¿è®­ç»ƒæ—¥å¿—å®æ—¶æ˜¾ç¤ºã€‚

python3 -m verl.trainer.main_ppoï¼šè¿è¡Œ PPO å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡å—ã€‚

æ•°æ®é…ç½®
data.train_files=/home/.../train.parquet
data.val_files=/home/.../test.parquet
data.train_batch_size=16
data.max_prompt_length=512
data.max_response_length=256
æŒ‡å®šè®­ç»ƒæ•°æ®ä¸éªŒè¯æ•°æ®çš„ Parquet æ–‡ä»¶è·¯å¾„ã€‚

è®¾ç½®è®­ç»ƒ batch å¤§å°ä¸º 16ã€‚

é™åˆ¶æ¨¡å‹è¾“å…¥ï¼ˆpromptï¼‰æœ€å¤§é•¿åº¦ä¸º 512ï¼Œè¾“å‡ºï¼ˆresponseï¼‰æœ€å¤§é•¿åº¦ä¸º 256ã€‚

Actor æ¨¡å‹é…ç½®
actor_rollout_ref.model.path=Qwen/Qwen2.5-0.5B-Instruct
actor_rollout_ref.actor.optim.lr=1e-6
actor_rollout_ref.actor.ppo_mini_batch_size=4
actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=4

actor_rollout_ref.model.pathï¼šä½¿ç”¨ Qwen2.5-0.5B-Instruct ä½œä¸º Actor æ¨¡å‹ã€‚

lr=1e-6ï¼šActor çš„å­¦ä¹ ç‡è®¾ä¸º 1e-6ã€‚

mini_batch æ˜¯ PPO æ¯è½®è¿­ä»£ä½¿ç”¨çš„å°æ‰¹é‡å¤§å°ï¼›micro_batch æ˜¯åœ¨ GPU ä¸Šå®é™…æ‰§è¡Œçš„ batch å¤§å°ï¼ˆç”¨äºæ˜¾å­˜æ§åˆ¶ï¼‰ã€‚


Rollout é…ç½®ï¼ˆç”ŸæˆåŠ¨ä½œ/é‡‡æ ·ï¼‰
actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=8
actor_rollout_ref.rollout.tensor_model_parallel_size=1
actor_rollout_ref.rollout.gpu_memory_utilization=0.4
æ§åˆ¶ rollout é˜¶æ®µæ¯ GPU çš„ batch å¤§å°ï¼ˆç”¨äºè®¡ç®— log probabilityï¼‰ã€‚

æŒ‡å®šå¹¶è¡Œåº¦ä¸º 1ï¼ˆä¸å¼€ tensor/model å¹¶è¡Œï¼‰ã€‚

ä½¿ç”¨ GPU æ˜¾å­˜çš„æœ€å¤§æ¯”ä¾‹ä¸º 0.4ï¼ˆé˜²æ­¢ OOMï¼‰

Reference æ¨¡å‹é…ç½®
actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4
reference model è´Ÿè´£å¯¹è¾“å‡ºè¿›è¡Œæ‰“åˆ†ï¼ˆlog_probï¼‰ï¼Œç”¨äºè®¡ç®—å¥–åŠ±å’Œ KL lossã€‚

Critic æ¨¡å‹é…ç½®
critic.model.path=Qwen/Qwen2.5-0.5B-Instruct
critic.optim.lr=1e-5
critic.ppo_micro_batch_size_per_gpu=4
ä½¿ç”¨åŒæ ·çš„æ¨¡å‹ä½œä¸º criticã€‚

critic å­¦ä¹ ç‡ä¸º 1e-5ã€‚

critic åœ¨æ¯ä¸ª GPU ä¸Šä½¿ç”¨çš„ micro batch sizeã€‚

algorithm.kl_ctrl.kl_coef=0.001
PPO ä¸­ç”¨äºæ§åˆ¶ Actor å’Œ Reference ä¹‹é—´çš„å·®å¼‚çš„ KL æƒ©ç½šç³»æ•°ã€‚è¶Šå¤§ï¼ŒActor è¶Šä¸æ•¢åç¦» Referenceã€‚


Traineré…ç½®
bash
å¤åˆ¶
ç¼–è¾‘
trainer.logger=console
trainer.val_before_train=False
trainer.n_gpus_per_node=1
trainer.nnodes=1
trainer.save_freq=10
trainer.test_freq=10
trainer.total_epochs=3
ä½¿ç”¨ console æ—¥å¿—å™¨ï¼ˆè€Œé wandb ç­‰ï¼‰ã€‚

val_before_train=Falseï¼šè·³è¿‡è®­ç»ƒå‰çš„éªŒè¯ã€‚

ä½¿ç”¨ 1 å¼  GPUï¼Œå•èŠ‚ç‚¹è®­ç»ƒã€‚

æ¯è®­ç»ƒ 10 ä¸ª epoch è¿›è¡Œä¸€æ¬¡ä¿å­˜å’Œæµ‹è¯•ã€‚

æ€»å…±è®­ç»ƒ 3 ä¸ª epochã€‚


# Actorï¼ˆæ¼”å‘˜ï¼‰
æ ¸å¿ƒæ¨¡å‹ï¼Œåœ¨è®­ç»ƒä¸­ä¸æ–­è°ƒæ•´æƒé‡ä»¥ä¼˜åŒ–å›ç­”è´¨é‡ã€‚

åœ¨æ¯ä¸ªè®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¥å—ä¸€ä¸ª promptï¼ˆè¾“å…¥ï¼‰ï¼Œç„¶åç”Ÿæˆ responseï¼ˆè¾“å‡ºï¼‰ã€‚

æ¨¡å‹çš„è¡Œä¸ºä¼šæ ¹æ® rewardï¼ˆç”± critic ç»™å‡ºï¼‰æ¥æ›´æ–°ï¼Œä½¿å…¶æ›´ç¬¦åˆäººç±»åå¥½æˆ–ç›®æ ‡ä»»åŠ¡ã€‚

Actor ä¼šå°è¯•ç”Ÿæˆç­–ç•¥ Ï€_Î¸ï¼Œå¹¶é€šè¿‡ PPO ç®—æ³•è¿›è¡Œç¨³å®šæ›´æ–°ï¼Œä½¿å…¶æ¯” Reference æ›´å¥½ï¼ˆæ›´é«˜ rewardï¼‰ã€‚

# Criticï¼ˆè¯„è®ºå®¶ï¼‰
è´Ÿè´£ç»™ Actor çš„è¾“å‡ºæ‰“åˆ†ï¼ˆå³ rewardï¼‰
å¯¹æ¯ä¸ª prompt å’Œ Actor è¾“å‡ºçš„ responseï¼Œé¢„æµ‹ä¸€ä¸ª reward åˆ†æ•°ï¼ˆç”¨ä½œ PPO ä¸­çš„ä»·å€¼å‡½æ•° V(s)ï¼‰ã€‚

Critic æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ª å›å½’æ¨¡å‹ï¼Œè¾“å‡º reward æœŸæœ›ã€‚

å®ƒæ˜¯ç›‘ç£ Actor å­¦ä¼šä»€ä¹ˆæ ·çš„å›ç­”æ˜¯â€œå¥½çš„â€çš„ä¾æ®ã€‚

# Referenceï¼ˆå‚è€ƒæ¨¡å‹ï¼‰
 Reference æ¨¡å‹ï¼šç”¨æ¥é™åˆ¶ Actor åç¦»å¤ªè¿œ
å†»ç»“ä¸æ›´æ–°ï¼Œä½œä¸º Actor çš„æ—§ç‰ˆæœ¬ã€‚

ç”¨æ¥è®¡ç®— KL æ•£åº¦ï¼ˆActor çš„è¾“å‡ºä¸ Reference çš„å·®è·ï¼‰ï¼Œé˜²æ­¢æ¨¡å‹è®­ç»ƒè¿‡åº¦åç¦»åˆå§‹èƒ½åŠ›ï¼ˆå³ä¿æŒâ€œåŸæ ·æ€§â€ï¼‰ã€‚

è¶Šåç¦»ï¼Œæƒ©ç½šè¶Šå¤§ï¼ˆé€šè¿‡ KL lossï¼‰ï¼Œæ§åˆ¶æ¨¡å‹å­¦ä¹ çš„â€œæ¿€è¿›ç¨‹åº¦â€ã€‚

Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Actor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Response
                    â”‚                        â”‚
                    â–¼                        â–¼
             Reference Model          Criticï¼ˆæ‰“åˆ†ï¼‰
                    â”‚                        â”‚
                    â–¼                        â–¼
             KL divergence             Reward Value
                    â”‚                        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                           â”‚            â”‚
                    PPO æ›´æ–°ç­–ç•¥       PPO æ›´æ–°Critic


Maxwell-Jia/AIME_2024


# verlé…ç½®æ–‡ä»¶è·¯å¾„
[evaluation.yaml](..%2Fverl%2Fverl%2Ftrainer%2Fconfig%2Fevaluation.yaml)
[generation.yaml](..%2Fverl%2Fverl%2Ftrainer%2Fconfig%2Fgeneration.yaml)
[ppo_megatron_trainer.yaml](..%2Fverl%2Fverl%2Ftrainer%2Fconfig%2Fppo_megatron_trainer.yaml)
[ppo_trainer.yaml](..%2Fverl%2Fverl%2Ftrainer%2Fconfig%2Fppo_trainer.yaml)
[sft_trainer.yaml](..%2Fverl%2Fverl%2Ftrainer%2Fconfig%2Fsft_trainer.yaml)

# RLçš„æ•°æ®é›†ä¸­çš„interaction_kwargså­—æ®µçš„æ„æ€
https://verl.readthedocs.io/en/latest/sglang_multiturn/interaction_system.html?utm_source=chatgpt.com
ä¸ç‰¹å®šæ ·æœ¬å¯¹åº”çš„äº¤äº’é€»è¾‘å‚æ•°ï¼Œ Rollout é˜¶æ®µï¼ˆsglang_rollout.pyï¼‰ ï¼Œåœ¨å®é™… rollout è¿‡ç¨‹ä¸­ï¼Œå½“è¯·æ±‚çŠ¶æ€ä¸º INTERACTING æ—¶ï¼Œç³»ç»Ÿä¼šè¯»å– _req.interaction_kwargs ä¸­çš„ "name" å­—æ®µæ¥é€‰æ‹©äº¤äº’ agentï¼š
ç„¶åè°ƒç”¨å¯¹åº”çš„äº¤äº’ç±»å®ä¾‹å¼•å¯¼å¤šè½®å¯¹è¯ã€æä¾›åé¦ˆã€è®¡ç®—å¥–åŠ±ç­‰ï¼Œverl äº¤äº’ç³»ç»Ÿåœ¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒæœŸé—´æ”¯æŒåŠ¨æ€ã€å¤šè½®å¯¹è¯åé¦ˆã€‚è¯¥ç³»ç»Ÿå…è®¸æ¨¡å‹å‚ä¸è¿­ä»£é—®é¢˜è§£å†³åœºæ™¯ï¼Œäº¤äº’ä»£ç†å¯ä»¥æ ¹æ®æ¨¡å‹çš„å“åº”æä¾›çº æ­£åé¦ˆã€æŒ‡å¯¼æˆ–è¯„ä¼°ã€‚
å‚è€ƒï¼š verl/interactions/gsm8k_interaction.py
Verl æ¡†æ¶ä¸­ç”¨äº GSM8K ä»»åŠ¡çš„äº¤äº’ä»£ç†ç±» Gsm8kInteractionï¼Œå®ƒç»§æ‰¿è‡ª BaseInteractionï¼Œç”¨äºæŒ‡å¯¼è®­ç»ƒæ¨¡å‹åœ¨ RLHF æˆ– DPO è¿‡ç¨‹ä¸­é€šè¿‡å¤šè½®äº¤äº’æ–¹å¼æå‡æ•°å­¦é¢˜çš„è§£ç­”èƒ½åŠ›ã€‚
ğŸ’¡ interaction_kwargs åœ¨å“ªä½“ç°ï¼Ÿ
äº¤äº’æµç¨‹æ˜¯å›´ç»•æ ·æœ¬æºå¸¦çš„ interaction_kwargs æ¥é…ç½®çš„ï¼Œä¾‹å¦‚ï¼š
{
  "name": "gsm8k",
  "query": "Samantha has 12 apples, eats 3...",
  "ground_truth": "The correct answer is 9."
}
Verl åœ¨ rollout é˜¶æ®µï¼š
è°ƒç”¨ interaction = interaction_map["gsm8k"]
ç”¨ start_interaction(ground_truth="The correct answer is 9.") å¯åŠ¨çŠ¶æ€
æ¨¡å‹è¾“å‡ºåï¼Œgenerate_response() åˆ¤æ–­ç­”é¢˜å¯¹é”™
ç»™å‡ºå¥–åŠ±å’Œç¯å¢ƒåé¦ˆï¼ˆç”¨äºä¸‹ä¸€æ­¥è®­ç»ƒæˆ– samplingï¼‰