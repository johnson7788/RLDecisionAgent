# Parquet
Parquet æ˜¯ä¸€ç§åˆ—å¼å­˜å‚¨æ ¼å¼ï¼ˆColumnar Storage Formatï¼‰ï¼Œä¸“ä¸ºé«˜æ•ˆå­˜å‚¨å’Œå¤„ç†å¤§è§„æ¨¡æ•°æ®è€Œè®¾è®¡ï¼Œç‰¹åˆ«é€‚åˆå¤§æ•°æ®å¤„ç†å’Œåˆ†æåœºæ™¯ã€‚å®ƒæ˜¯ Apache å¼€å‘çš„å¼€æºé¡¹ç›®ï¼Œå¸¸ç”¨äº Hadoopã€Sparkã€Hiveã€Prestoã€Pandas ç­‰æ•°æ®å¤„ç†ç³»ç»Ÿä¸­ã€‚
```python
import pandas as pd

# ä¿å­˜ DataFrame ä¸º Parquet
df = pd.DataFrame({'a': [1, 2], 'b': ['x', 'y']})
df.to_parquet('train.parquet', engine='pyarrow')

# è¯»å– Parquet æ–‡ä»¶
df2 = pd.read_parquet('train.parquet', engine='pyarrow')
print(df2)
```

# è®­ç»ƒå‘½ä»¤è§£æ
PYTHONUNBUFFERED=1 python3 -m verl.trainer.main_ppo ...
PYTHONUNBUFFERED=1ï¼šè¾“å‡ºä¸ç¼“å†²ï¼Œç¡®ä¿è®­ç»ƒæ—¥å¿—å®æ—¶æ˜¾ç¤ºã€‚

python3 -m verl.trainer.main_ppoï¼šè¿è¡Œ PPO å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡å—ã€‚

æ•°æ®é…ç½®
data.train_files=/home/.../train.parquet
data.val_files=/home/.../test.parquet
data.train_batch_size=16
data.max_prompt_length=512
data.max_response_length=256
æŒ‡å®šè®­ç»ƒæ•°æ®ä¸éªŒè¯æ•°æ®çš„ Parquet æ–‡ä»¶è·¯å¾„ã€‚

è®¾ç½®è®­ç»ƒ batch å¤§å°ä¸º 16ã€‚

é™åˆ¶æ¨¡å‹è¾“å…¥ï¼ˆpromptï¼‰æœ€å¤§é•¿åº¦ä¸º 512ï¼Œè¾“å‡ºï¼ˆresponseï¼‰æœ€å¤§é•¿åº¦ä¸º 256ã€‚

Actor æ¨¡å‹é…ç½®
actor_rollout_ref.model.path=Qwen/Qwen2.5-0.5B-Instruct
actor_rollout_ref.actor.optim.lr=1e-6
actor_rollout_ref.actor.ppo_mini_batch_size=4
actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=4

actor_rollout_ref.model.pathï¼šä½¿ç”¨ Qwen2.5-0.5B-Instruct ä½œä¸º Actor æ¨¡å‹ã€‚

lr=1e-6ï¼šActor çš„å­¦ä¹ ç‡è®¾ä¸º 1e-6ã€‚

mini_batch æ˜¯ PPO æ¯è½®è¿­ä»£ä½¿ç”¨çš„å°æ‰¹é‡å¤§å°ï¼›micro_batch æ˜¯åœ¨ GPU ä¸Šå®é™…æ‰§è¡Œçš„ batch å¤§å°ï¼ˆç”¨äºæ˜¾å­˜æ§åˆ¶ï¼‰ã€‚


Rollout é…ç½®ï¼ˆç”ŸæˆåŠ¨ä½œ/é‡‡æ ·ï¼‰
actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=8
actor_rollout_ref.rollout.tensor_model_parallel_size=1
actor_rollout_ref.rollout.gpu_memory_utilization=0.4
æ§åˆ¶ rollout é˜¶æ®µæ¯ GPU çš„ batch å¤§å°ï¼ˆç”¨äºè®¡ç®— log probabilityï¼‰ã€‚

æŒ‡å®šå¹¶è¡Œåº¦ä¸º 1ï¼ˆä¸å¼€ tensor/model å¹¶è¡Œï¼‰ã€‚

ä½¿ç”¨ GPU æ˜¾å­˜çš„æœ€å¤§æ¯”ä¾‹ä¸º 0.4ï¼ˆé˜²æ­¢ OOMï¼‰

Reference æ¨¡å‹é…ç½®
actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4
reference model è´Ÿè´£å¯¹è¾“å‡ºè¿›è¡Œæ‰“åˆ†ï¼ˆlog_probï¼‰ï¼Œç”¨äºè®¡ç®—å¥–åŠ±å’Œ KL lossã€‚

Critic æ¨¡å‹é…ç½®
critic.model.path=Qwen/Qwen2.5-0.5B-Instruct
critic.optim.lr=1e-5
critic.ppo_micro_batch_size_per_gpu=4
ä½¿ç”¨åŒæ ·çš„æ¨¡å‹ä½œä¸º criticã€‚

critic å­¦ä¹ ç‡ä¸º 1e-5ã€‚

critic åœ¨æ¯ä¸ª GPU ä¸Šä½¿ç”¨çš„ micro batch sizeã€‚

algorithm.kl_ctrl.kl_coef=0.001
PPO ä¸­ç”¨äºæ§åˆ¶ Actor å’Œ Reference ä¹‹é—´çš„å·®å¼‚çš„ KL æƒ©ç½šç³»æ•°ã€‚è¶Šå¤§ï¼ŒActor è¶Šä¸æ•¢åç¦» Referenceã€‚


Traineré…ç½®
bash
å¤åˆ¶
ç¼–è¾‘
trainer.logger=console
trainer.val_before_train=False
trainer.n_gpus_per_node=1
trainer.nnodes=1
trainer.save_freq=10
trainer.test_freq=10
trainer.total_epochs=3
ä½¿ç”¨ console æ—¥å¿—å™¨ï¼ˆè€Œé wandb ç­‰ï¼‰ã€‚

val_before_train=Falseï¼šè·³è¿‡è®­ç»ƒå‰çš„éªŒè¯ã€‚

ä½¿ç”¨ 1 å¼  GPUï¼Œå•èŠ‚ç‚¹è®­ç»ƒã€‚

æ¯è®­ç»ƒ 10 ä¸ª epoch è¿›è¡Œä¸€æ¬¡ä¿å­˜å’Œæµ‹è¯•ã€‚

æ€»å…±è®­ç»ƒ 3 ä¸ª epochã€‚


# Actorï¼ˆæ¼”å‘˜ï¼‰
æ ¸å¿ƒæ¨¡å‹ï¼Œåœ¨è®­ç»ƒä¸­ä¸æ–­è°ƒæ•´æƒé‡ä»¥ä¼˜åŒ–å›ç­”è´¨é‡ã€‚

åœ¨æ¯ä¸ªè®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¥å—ä¸€ä¸ª promptï¼ˆè¾“å…¥ï¼‰ï¼Œç„¶åç”Ÿæˆ responseï¼ˆè¾“å‡ºï¼‰ã€‚

æ¨¡å‹çš„è¡Œä¸ºä¼šæ ¹æ® rewardï¼ˆç”± critic ç»™å‡ºï¼‰æ¥æ›´æ–°ï¼Œä½¿å…¶æ›´ç¬¦åˆäººç±»åå¥½æˆ–ç›®æ ‡ä»»åŠ¡ã€‚

Actor ä¼šå°è¯•ç”Ÿæˆç­–ç•¥ Ï€_Î¸ï¼Œå¹¶é€šè¿‡ PPO ç®—æ³•è¿›è¡Œç¨³å®šæ›´æ–°ï¼Œä½¿å…¶æ¯” Reference æ›´å¥½ï¼ˆæ›´é«˜ rewardï¼‰ã€‚

# Criticï¼ˆè¯„è®ºå®¶ï¼‰
è´Ÿè´£ç»™ Actor çš„è¾“å‡ºæ‰“åˆ†ï¼ˆå³ rewardï¼‰
å¯¹æ¯ä¸ª prompt å’Œ Actor è¾“å‡ºçš„ responseï¼Œé¢„æµ‹ä¸€ä¸ª reward åˆ†æ•°ï¼ˆç”¨ä½œ PPO ä¸­çš„ä»·å€¼å‡½æ•° V(s)ï¼‰ã€‚

Critic æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ª å›å½’æ¨¡å‹ï¼Œè¾“å‡º reward æœŸæœ›ã€‚

å®ƒæ˜¯ç›‘ç£ Actor å­¦ä¼šä»€ä¹ˆæ ·çš„å›ç­”æ˜¯â€œå¥½çš„â€çš„ä¾æ®ã€‚

# Referenceï¼ˆå‚è€ƒæ¨¡å‹ï¼‰
 Reference æ¨¡å‹ï¼šç”¨æ¥é™åˆ¶ Actor åç¦»å¤ªè¿œ
å†»ç»“ä¸æ›´æ–°ï¼Œä½œä¸º Actor çš„æ—§ç‰ˆæœ¬ã€‚

ç”¨æ¥è®¡ç®— KL æ•£åº¦ï¼ˆActor çš„è¾“å‡ºä¸ Reference çš„å·®è·ï¼‰ï¼Œé˜²æ­¢æ¨¡å‹è®­ç»ƒè¿‡åº¦åç¦»åˆå§‹èƒ½åŠ›ï¼ˆå³ä¿æŒâ€œåŸæ ·æ€§â€ï¼‰ã€‚

è¶Šåç¦»ï¼Œæƒ©ç½šè¶Šå¤§ï¼ˆé€šè¿‡ KL lossï¼‰ï¼Œæ§åˆ¶æ¨¡å‹å­¦ä¹ çš„â€œæ¿€è¿›ç¨‹åº¦â€ã€‚

Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Actor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Response
                    â”‚                        â”‚
                    â–¼                        â–¼
             Reference Model          Criticï¼ˆæ‰“åˆ†ï¼‰
                    â”‚                        â”‚
                    â–¼                        â–¼
             KL divergence             Reward Value
                    â”‚                        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                           â”‚            â”‚
                    PPO æ›´æ–°ç­–ç•¥       PPO æ›´æ–°Critic


Maxwell-Jia/AIME_2024


# verlé…ç½®æ–‡ä»¶è·¯å¾„
[evaluation.yaml](..%2Fverl%2Fverl%2Ftrainer%2Fconfig%2Fevaluation.yaml)
[generation.yaml](..%2Fverl%2Fverl%2Ftrainer%2Fconfig%2Fgeneration.yaml)
[ppo_megatron_trainer.yaml](..%2Fverl%2Fverl%2Ftrainer%2Fconfig%2Fppo_megatron_trainer.yaml)
[ppo_trainer.yaml](..%2Fverl%2Fverl%2Ftrainer%2Fconfig%2Fppo_trainer.yaml)
[sft_trainer.yaml](..%2Fverl%2Fverl%2Ftrainer%2Fconfig%2Fsft_trainer.yaml)

## evaluation.yaml
data:
  path: /tmp/math_Qwen2-7B-Instruct.parquet
  prompt_key: prompt
  response_key: responses
  data_source_key: data_source
  reward_model_key: reward_model
pathï¼šæŒ‡å®šè¯„ä¼°æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œåº”ä¸º .parquet æ–‡ä»¶ã€‚

prompt_keyï¼šç”¨äºä»æ•°æ®ä¸­æå–è¾“å…¥æç¤ºçš„å­—æ®µåã€‚

response_keyï¼šè¡¨ç¤ºæ¨¡å‹ç”Ÿæˆå“åº”ï¼ˆç”Ÿæˆçš„ç­”æ¡ˆï¼‰å­—æ®µï¼Œé€šå¸¸æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ã€‚

data_source_keyï¼šç”¨äºåŒºåˆ†ä¸åŒæ•°æ®æ¥æºï¼Œåœ¨è¯„ä¼°æ—¶å¯åˆ†åˆ«è®¡ç®—å„æ¥æºçš„æŒ‡æ ‡ã€‚

reward_model_keyï¼šä»£è¡¨â€œå‚è€ƒç­”æ¡ˆâ€æˆ–è¯„åˆ†æ¨¡å‹è¾“å‡ºçš„å­—æ®µåï¼Œç”¨äºä¸ç”Ÿæˆè¾“å‡ºåšå¯¹æ¯”ã€‚


custom_reward_function:
  path: null
  name: compute_score
pathï¼šæŒ‡å®šåŒ…å«è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°çš„ Python æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœä¸º nullï¼Œå°†ä½¿ç”¨å†…ç½®çš„é¢„è®¾å‡½æ•°ã€‚
nameï¼šå‡½æ•°åï¼Œé»˜è®¤æ˜¯ compute_scoreã€‚å¦‚æœä½ åªå†™ä¸€ä¸ª compute_score å‡½æ•°ï¼Œå¯ä»¥ç®€å•ä½¿ç”¨é»˜è®¤å³å¯ã€‚

ray_initï¼ˆä¸ Ray åˆå§‹åŒ–ç›¸å…³ï¼‰
ray_init:
  num_cpus: null
  timeline_json_file: null
num_cpusï¼šç”¨äºæ§åˆ¶ Ray é›†ç¾¤ä½¿ç”¨çš„ CPU æ ¸å¿ƒæ•°ã€‚è‹¥ä¸º nullï¼ˆæˆ– Noneï¼‰ï¼Œé»˜è®¤ä½¿ç”¨ç³»ç»Ÿæ‰€æœ‰ CPUï¼Œä½†åœ¨ä¸€äº›é›†ç¾¤ç¯å¢ƒï¼ˆå¦‚ SLURMï¼‰å¯èƒ½ä¼šå¯¼è‡´å¡ä½ã€‚å»ºè®®æ˜ç¡®è®¾ç½®ä¸€ä¸ªå…è®¸ä½¿ç”¨çš„æ•°å­—ã€‚
timeline_json_fileï¼šå¯é€‰è·¯å¾„ï¼Œç”¨äºè¾“å‡º Ray Timeline çš„ JSON æ–‡ä»¶ï¼Œä¾¿äºè°ƒè¯•æ€§èƒ½é—®é¢˜ã€‚è‹¥ä¸éœ€è¦åˆ™è®¾ä¸º nullã€‚ã€

# generation.yaml
ä¸‹é¢æ˜¯å¯¹ä½ æä¾›çš„ `generation.yaml` é…ç½®é€é¡¹è§£é‡Šï¼Œç»“åˆ Verl å®˜æ–¹æ–‡æ¡£ä¸­çš„è¯´æ˜ï¼ˆæˆªè‡³ 2025 å¹´æ›´æ–°ï¼‰([Verl][1])ã€‚


## ğŸ§  Trainer è®¾ç½®

```yaml
trainer:
  nnodes: 1
  n_gpus_per_node: 8
  device: cuda
```

* **`nnodes`** ä¸ **`n_gpus_per_node`**ï¼šé…ç½®ç”¨äºç”Ÿæˆçš„èŠ‚ç‚¹æ•°å’Œæ¯èŠ‚ç‚¹ GPU æ•°é‡ï¼Œæ”¯æŒå¤šèŠ‚ç‚¹è®­ç»ƒï¼generationã€‚
* **`device`**ï¼šä½¿ç”¨ GPU (`cuda`) è€Œé CPUã€‚

---

## ğŸ“‚ Data éƒ¨åˆ†

```yaml
data:
  path: ~/data/rlhf/math/test.parquet
  prompt_key: prompt
  n_samples: 5
  output_path: /opt/tiger/math_Qwen2-7B-Instruct.parquet
  batch_size: 128
```

* **`path`**ï¼šè¾“å…¥æ•°æ®æºï¼Œé€šå¸¸æ˜¯ `.parquet` æ ¼å¼ã€‚
* **`prompt_key`**ï¼šæ•°æ®ä¸­çš„æç¤ºå­—æ®µåï¼ˆpromptï¼‰ã€‚
* **`n_samples`**ï¼šæ¯ä¸ª prompt ç”Ÿæˆå¤šå°‘ä¸ªç­”æ¡ˆæ ·æœ¬ï¼ˆè¿™é‡Œä¸º 5ï¼‰ã€‚
* **`output_path`**ï¼šç”Ÿæˆçš„æ ·æœ¬å°†ä¿å­˜åˆ°è¯¥è·¯å¾„ã€‚
* **`batch_size`**ï¼šä¸€æ¬¡å¤„ç†å¤šå°‘ promptï¼Œä»¥æé«˜å¹¶è¡Œååã€‚

---

## ğŸ§± Model é…ç½®

```yaml
model:
  path: ~/models/Qwen2-7B-Instruct
  external_lib: null
```

* **`path`**ï¼šæŒ‡å®šç”¨äºæ¨ç†æˆ–ç”Ÿæˆçš„æ¨¡å‹è·¯å¾„ã€‚
* **`external_lib`**ï¼šå¦‚ä¸º null ä½¿ç”¨é»˜è®¤åº“ï¼Œä¹Ÿå¯ä»¥æŒ‡å®šè‡ªå®šä¹‰åº“ï¼ˆä¾‹å¦‚æœ‰ç‰¹æ®Š tokenizer æˆ–åå¤„ç†ï¼‰ã€‚

---

## ğŸ”„ Rollout æ¨¡å—

```yaml
rollout:
  name: vllm
  mode: sync
  temperature: 1.0
  top_k: 50
  top_p: 0.7
  prompt_length: 1536
  response_length: 512
  dtype: bfloat16
  gpu_memory_utilization: 0.5
  ignore_eos: False
  enforce_eager: True
  free_cache_engine: True
  load_format: dummy_dtensor
  tensor_model_parallel_size: 1
  max_num_batched_tokens: 8192
  max_num_seqs: 1024
  log_prob_micro_batch_size_per_gpu: 8
  do_sample: True
  disable_log_stats: True
  enable_chunked_prefill: True
  n: 1
  calculate_log_probs: False
```

### ğŸ¯ åŸºç¡€é‡‡æ ·å‚æ•°

* **`name: vllm`**ï¼šé€‰æ‹© vLLM ä½œä¸º rollout engineã€‚
* **`mode: sync`**ï¼šåŒæ­¥æ¨¡å¼ï¼ˆasync è¡¨ç¤ºä½¿ç”¨ AsyncLLMï¼‰ã€‚
* **`temperature`ã€`top_k`ã€`top_p`**ï¼šæ§åˆ¶é‡‡æ ·ç­–ç•¥çš„éšæœºæ€§ä¸å¤šæ ·æ€§([Verl][1], [vLLM Forums][2])ã€‚

### âš™ï¸ vLLM ç‰¹å®šè®¾ç½®

* **`dtype: bfloat16`**ï¼šæŒ‡å®šç”Ÿæˆä½¿ç”¨çš„æµ®ç‚¹ç±»å‹ï¼Œä¸è®­ç»ƒ actor æ¨¡å‹ä¿æŒä¸€è‡´([Verl][1])ã€‚
* **`gpu_memory_utilization: 0.5`**ï¼švLLM å ç”¨ GPU æ€»å†…å­˜çš„æ¯”ä¾‹ï¼Œé€šå¸¸è®¾ 0.5â€“0.7 ä»¥å¹³è¡¡ååä¸ OOM é£é™©([Verl][1])ã€‚
* **`ignore_eos`**ï¼šä¸åœ¨ç”Ÿæˆç»“æŸæ—¶å› é‡ EOS token è€Œåœæ­¢ã€‚
* **`enforce_eager`**ï¼šå…³é—­ CUDA å›¾ï¼ˆCUDAGraphï¼‰ï¼Œé¿å… vLLM æŸäº›ç‰ˆæœ¬åœ¨ç¼“å­˜é‡Šæ”¾è¿‡ç¨‹ä¸­å´©æºƒ([Verl][1])ã€‚
* **`free_cache_engine`**ï¼šç”Ÿæˆåé‡Šæ”¾ KV cacheï¼Œé…åˆ `enforce_eager=True` ä»¥é™ä½å†…å­˜ã€‚
* **`load_format`**ï¼š`dummy_dtensor` ç”¨äº FSDP åç«¯çš„è™šæ‹Ÿåˆå§‹åŒ–æ–¹å¼ï¼Œå»¶è¿Ÿå®ç°æƒé‡åŒæ­¥([Verl][1])ã€‚
* **`tensor_model_parallel_size: 1`**ï¼šTP sizeï¼Œåªä½¿ç”¨ 1 ä»½ vLLM å‰¯æœ¬ã€‚

### æ‰¹é‡è°ƒä¼˜å‚æ•°

* **`max_num_batched_tokens: 8192`** å’Œ **`max_num_seqs: 1024`**ï¼šæ§åˆ¶æ¯æ¬¡ç”Ÿæˆæ—¶å¤„ç†çš„ token å’Œåºåˆ—æ•°ã€‚å¢å¤§å¯æé«˜ååæ€§èƒ½([Verl][1], [Verl][3])ã€‚
* **`log_prob_micro_batch_size_per_gpu: 8`**ï¼šæ¯ä¸ª GPU ç”¨äº logâ€‘prob è®¡ç®—çš„å°æ‰¹é‡å¤§å°ï¼ˆæ›¿ä»£è¿‡æ—¶ `log_prob_micro_batch_size`ï¼‰([Verl][1])ã€‚

### HF Rollout æ¨¡å¼å‚æ•°ï¼ˆå…¼å®¹æ€§ï¼‰

* **`do_sample`**ï¼šæ˜¯å¦é‡‡æ ·ï¼ˆä¸ greedyï¼‰ã€‚
* **`disable_log_stats`**ã€**`enable_chunked_prefill`**ï¼šå¯ç”¨äºç»Ÿè®¡æ—¥å¿—æ§åˆ¶ä¸å†…å­˜åˆ†å—é¢„å¡«å……ä¼˜åŒ–ã€‚
* **`n`**ï¼šæ¯ä¸ª prompt è¾“å‡ºæ¡æ•°ï¼Œé€šå¸¸ä¸º 1ã€‚

### è°ƒè¯•é€‰é¡¹

* **`calculate_log_probs: False`**ï¼šæ˜¯å¦åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­è®°å½• logâ€‘probï¼Œæ–¹ä¾¿è°ƒè¯•ä½†ä¼šå½±å“æ€§èƒ½ã€‚

---

## ğŸ¬ Actor æ¨¡å‹ç»†èŠ‚ï¼ˆActor Rolloutï¼‰

```yaml
actor:
  strategy: fsdp
  ulysses_sequence_parallel_size: 1
  entropy_from_logits_with_chunking: False
  entropy_checkpointing: False
  fsdp_config:
    fsdp_size: -1
    forward_prefetch: False
```

* **`strategy: fsdp`**ï¼šä½¿ç”¨ PyTorch FSDP åç«¯è®­ç»ƒ actorã€‚
* **å¹¶è¡Œä¸ç†µè®¡ç®—ç›¸å…³è®¾ç½®**ï¼ˆå¦‚ Ulysses parallel, checkpointingï¼‰æ˜¯ç”¨äºå†…å­˜ä¼˜åŒ–å’Œååæå‡çš„ç»†èŠ‚é€‰é¡¹ã€‚

---

## â˜ï¸ Ray åˆå§‹åŒ–ï¼ˆä¸ evaluation.yaml ä¸€è‡´ï¼‰

```yaml
ray_init:
  num_cpus: null
  timeline_json_file: null
```

* **`num_cpus: null`**ï¼šé»˜è®¤ä½¿ç”¨ç³»ç»Ÿå…¨éƒ¨ CPUï¼Œå»ºè®®åœ¨ SLURM ç­‰é›†ç¾¤ç¯å¢ƒä¸­è®¾ç½®ä¸ºç‰¹å®šå€¼ä»¥é¿å… hangã€‚
* **`timeline_json_file`**ï¼šå¯å†™å…¥ Ray æ€§èƒ½ timeline JSONï¼Œä»¥ç”¨äºè°ƒè¯•ã€‚

---

## âœ… æ€»ç»“ä¸€è§ˆ

| æ¨¡å—            | é…ç½®é¡¹                             | è¯´æ˜              |
| ------------- | ------------------------------- | --------------- |
| **trainer**   | nnodes / n\_gpus\_per\_node     | å¤šèŠ‚ç‚¹ä¸ GPU æ•°è®¾ç½®    |
|               | device                          | ä½¿ç”¨ GPU æˆ– CPU    |
| **data**      | n\_samples / batch\_size        | å¤šæ ·æœ¬ç”ŸæˆåŠå¹¶è¡Œåå      |
| **model**     | path / external\_lib            | æ¨¡å‹è·¯å¾„ä¸è‡ªå®šä¹‰åº“       |
| **rollout**   | name, mode                      | rollout å¼•æ“ä¸è°ƒç”¨æ¨¡å¼ |
|               | temperature, top\_k, top\_p     | ç”Ÿæˆç­–ç•¥æ§åˆ¶          |
|               | dtype, gpu\_memory\_utilization | å†…å­˜ç±»å‹åŠå ç”¨æ¯”ä¾‹       |
|               | load\_format                    | æƒé‡åŠ è½½æ–¹å¼åŒ¹é…è®­ç»ƒåç«¯    |
|               | batched\_tokens, seqs           | æ‰¹å¤„ç†è§„æ¨¡æ§åˆ¶         |
| **actor**     | fsdp / Ulysses parallel ç­‰       | actor è®­ç»ƒè¡Œä¸ºä¸ä¼˜åŒ–å¼€å…³ |
| **ray\_init** | num\_cpus, timeline\_json\_file | Ray èµ„æºæ§åˆ¶ä¸è°ƒè¯•è¾…åŠ©   |





# RLçš„æ•°æ®é›†ä¸­çš„interaction_kwargså­—æ®µçš„æ„æ€
https://verl.readthedocs.io/en/latest/sglang_multiturn/interaction_system.html?utm_source=chatgpt.com
ä¸ç‰¹å®šæ ·æœ¬å¯¹åº”çš„äº¤äº’é€»è¾‘å‚æ•°ï¼Œ Rollout é˜¶æ®µï¼ˆsglang_rollout.pyï¼‰ ï¼Œåœ¨å®é™… rollout è¿‡ç¨‹ä¸­ï¼Œå½“è¯·æ±‚çŠ¶æ€ä¸º INTERACTING æ—¶ï¼Œç³»ç»Ÿä¼šè¯»å– _req.interaction_kwargs ä¸­çš„ "name" å­—æ®µæ¥é€‰æ‹©äº¤äº’ agentï¼š
ç„¶åè°ƒç”¨å¯¹åº”çš„äº¤äº’ç±»å®ä¾‹å¼•å¯¼å¤šè½®å¯¹è¯ã€æä¾›åé¦ˆã€è®¡ç®—å¥–åŠ±ç­‰ï¼Œverl äº¤äº’ç³»ç»Ÿåœ¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒæœŸé—´æ”¯æŒåŠ¨æ€ã€å¤šè½®å¯¹è¯åé¦ˆã€‚è¯¥ç³»ç»Ÿå…è®¸æ¨¡å‹å‚ä¸è¿­ä»£é—®é¢˜è§£å†³åœºæ™¯ï¼Œäº¤äº’ä»£ç†å¯ä»¥æ ¹æ®æ¨¡å‹çš„å“åº”æä¾›çº æ­£åé¦ˆã€æŒ‡å¯¼æˆ–è¯„ä¼°ã€‚
å‚è€ƒï¼š verl/interactions/gsm8k_interaction.py
Verl æ¡†æ¶ä¸­ç”¨äº GSM8K ä»»åŠ¡çš„äº¤äº’ä»£ç†ç±» Gsm8kInteractionï¼Œå®ƒç»§æ‰¿è‡ª BaseInteractionï¼Œç”¨äºæŒ‡å¯¼è®­ç»ƒæ¨¡å‹åœ¨ RLHF æˆ– DPO è¿‡ç¨‹ä¸­é€šè¿‡å¤šè½®äº¤äº’æ–¹å¼æå‡æ•°å­¦é¢˜çš„è§£ç­”èƒ½åŠ›ã€‚
ğŸ’¡ interaction_kwargs åœ¨å“ªä½“ç°ï¼Ÿ
äº¤äº’æµç¨‹æ˜¯å›´ç»•æ ·æœ¬æºå¸¦çš„ interaction_kwargs æ¥é…ç½®çš„ï¼Œä¾‹å¦‚ï¼š
{
  "name": "gsm8k",
  "query": "Samantha has 12 apples, eats 3...",
  "ground_truth": "The correct answer is 9."
}
Verl åœ¨ rollout é˜¶æ®µï¼š
è°ƒç”¨ interaction = interaction_map["gsm8k"]
ç”¨ start_interaction(ground_truth="The correct answer is 9.") å¯åŠ¨çŠ¶æ€
æ¨¡å‹è¾“å‡ºåï¼Œgenerate_response() åˆ¤æ–­ç­”é¢˜å¯¹é”™
ç»™å‡ºå¥–åŠ±å’Œç¯å¢ƒåé¦ˆï¼ˆç”¨äºä¸‹ä¸€æ­¥è®­ç»ƒæˆ– samplingï¼‰


# verlä¸­çš„multiturnå¤šè½®å¯¹è¯æ˜¯å¦‚ä½•è®¡ç®—å¥–åŠ±çš„ï¼Ÿ
å¤šè½®å¯¹è¯ï¼ˆmultiâ€‘turn dialogueï¼‰çš„å¥–åŠ±æœºåˆ¶é€šå¸¸æ˜¯åŸºäº æ¯ä¸ªå¯¹è¯å›åˆï¼ˆturn-levelï¼‰ æˆ– æ•´ä¸ªå¯¹è¯è½¨è¿¹ï¼ˆtrajectory-levelï¼‰ 
| æ–¹æ³•ç±»åˆ«                      | å¥–åŠ±æ—¶æœº           | å¥–åŠ±æ¥æº                                   | é€‚ç”¨åœºæ™¯                          |
| ------------------------- | -------------- | -------------------------------------- | ----------------------------- |
| **å›åˆçº§ï¼ˆturn-levelï¼‰**       | æ¯ä¸ªå›åˆå          | tool æ‰“åˆ†ï¼Œå¦‚ correctness                  | GSM8Kã€QA æ¯æ­¥æ‰“åˆ†å‹å¯¹è¯              |
| **è½¨è¿¹çº§ï¼ˆtrajectory-levelï¼‰** | å¯¹è¯ç»“æŸå          | æœ€ç»ˆæ˜¯å¦æ­£ç¡®ã€judge æ¨¡å‹è¾“å‡º                      | MGPOã€ARTISTã€agent agents ç±» RL |
| **æ··åˆæ¨¡å‹**                  | å…¼å…·å›åˆå†…è¯„åˆ†ä¸æœ€ç»ˆè½¨è¿¹å¥–åŠ± | proxy æˆ– correctness + information gain | ä¿¡æ¯ç¨€ç–ã€å¤šå›åˆæ¨ç†ä»»åŠ¡                  |

# RLè®­ç»ƒé›†ä¸­çš„agent_nameå­—æ®µ
RL æ•°æ®é›†ä¸­çš„ agent_name å­—æ®µä¸»è¦ç”¨äºæŒ‡å®šè®­ç»ƒæ—¶æ‰€ä½¿ç”¨çš„ä»£ç†å¾ªç¯ç­–ç•¥ï¼ˆagent loopï¼‰,åœ¨å¤šè½®äº¤äº’ï¼ˆmulti-turn conversationï¼‰å’Œå·¥å…·è°ƒç”¨ï¼ˆtool callsï¼‰åœºæ™¯ä¸­ï¼ŒTool Agent Loop è¦æ±‚æ•°æ®é›†é‡Œå¿…é¡»åŒ…å« "agent_name" å­—æ®µã€‚ç³»ç»Ÿä¼šä¾æ®è¯¥å­—æ®µå€¼ å†³å®šä½¿ç”¨ tool_agent_loop è¿˜æ˜¯ single_turn_agentï¼ˆé»˜è®¤ï¼‰ è¿›è¡Œåç»­ rollout å¤„ç†
| æ–‡ä»¶ / ç”¨ä¾‹                                                | agent\_name å€¼         | ä½œç”¨                           |
| ------------------------------------------------------ | --------------------- | ---------------------------- |
| GSM8K å·¥å…·è°ƒç”¨è®­ç»ƒè„šæœ¬ (`gsm8k_tool_agent_loop.py`)            | `"tool_agent"`        | ä½¿ç”¨å·¥å…·ä»£ç†å¾ªç¯ï¼Œå¼€å¯å·¥å…·è°ƒç”¨æ”¯æŒä¸è®¡ç®—å¥–åŠ±èåˆ     |
| Multiâ€‘turn React Agent æµ‹è¯• (`test_react_agent_loop.py`) | `"react_agent"`       | æµ‹è¯•å¸¦æœ‰å¤šè½® React è¡Œä¸ºçš„ agent loop  |
| å•è½®æµ‹è¯• (`test_basic_agent_loop.py`)                      | `"single_turn_agent"` | ä½¿ç”¨å•å›åˆä»£ç†é€»è¾‘ï¼Œæ— å·¥å…·è°ƒç”¨å‚ä¸            |
| æ•°å­¦è¡¨è¾¾å¼æ•°æ®ç”Ÿæˆ (`create_dataset.py`)                        | `"math_expression"`   | è‡ªå®šä¹‰ agent loop ç±»å‹ï¼Œç”¨äºç‰¹å®šæ•°å­¦è¡¨è¾¾ä»»åŠ¡ |

tool_agentï¼šç”¨äº GSM8K æ•°å­¦é¢˜ + å·¥å…·è°ƒç”¨è®­ç»ƒæµç¨‹ï¼Œä¼šä½¿ç”¨ ToolAgentLoop ç±»æ¥æ”¯æŒ stepâ€‘byâ€‘step æ¨ç†ã€è°ƒç”¨ calc_gsm8k_reward ç­‰å·¥å…·é€»è¾‘ã€‚

react_agentï¼šåœ¨ React Agentï¼ˆLangGraph é£æ ¼ï¼‰ä¸­ä½¿ç”¨ï¼Œç”¨äº multiâ€‘turn å·¥å…·è°ƒç”¨ + è‡ªåæ€æ¨ç†ç±»å‹æµç¨‹ã€‚

single_turn_agentï¼šé»˜è®¤å•è½®å“åº” agent loopï¼Œæ— å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œé€‚ç”¨äºç®€å•ä¸€æ¬¡æ€§å›ç­”æµç¨‹ã€‚

math_expressionï¼šè‡ªå®šä¹‰ agent loopï¼Œä¾‹å¦‚ç”¨äºç”Ÿæˆæ•°å­¦è¡¨è¾¾å¼ä»»åŠ¡çš„æµç¨‹é€»è¾‘ã€‚

cat ./verl/verl/experimental/agent_loop/__init__.py

./verl/verl/experimental/agent_loop/tool_agent_loop.py
verl ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒ agent loop runner ç±»å‹ï¼šToolAgentLoopã€‚å®ƒæ˜¯ä¸€ä¸ªåŸºäºå·¥å…·è°ƒç”¨çš„å¤šè½®å¯¹è¯ Agentï¼Œç”¨äºåœ¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒæˆ–æ¨ç†æ—¶ï¼Œè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨ã€ç”Ÿæˆå“åº”ã€ä»¥åŠä¸ç¯å¢ƒäº¤äº’ã€‚

æ¯è½®å¾ªç¯åŒ…æ‹¬ï¼š

è°ƒç”¨ LLM ç”Ÿæˆå“åº”ï¼ˆassistant å›åˆï¼‰ã€‚

è§£æå“åº”ä¸­æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ã€‚

å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œå°±æ‰§è¡Œå·¥å…·å¹¶ç”Ÿæˆ tool responseã€‚

å°† tool response æ‹¼æ¥è¿› promptï¼Œä½œä¸ºä¸‹ä¸€è½®è¾“å…¥ï¼ˆuser å›åˆï¼‰ã€‚

ç›´åˆ°è¾¾åˆ°è¿™äº›ç»ˆæ­¢æ¡ä»¶ä¹‹ä¸€ï¼š

è¾¾åˆ°æœ€å¤§ token é™åˆ¶ï¼ˆresponse_lengthï¼‰

è¾¾åˆ°æœ€å¤§ assistant turn æˆ– user turn

æ²¡æœ‰å·¥å…·è°ƒç”¨äº†

å·¥å…·è°ƒç”¨å¼‚å¸¸ï¼ˆå¦‚æŠ¥é”™


## ppo_trainer.yaml
è¿™ä¸ª `ppo_trainer.yaml` æ˜¯ **VERL**ï¼ˆVersatile RLHF Libraryï¼‰æ¡†æ¶ä¸­ç”¨äºé…ç½® **PPOï¼ˆProximal Policy Optimizationï¼‰è®­ç»ƒå™¨** çš„æ ¸å¿ƒé…ç½®æ–‡ä»¶ï¼Œé…ç½®å†…å®¹è¾ƒå¤šï¼Œä¸‹é¢æˆ‘ä¼šä»æ•´ä½“ç»“æ„å’Œå…³é”®å­—æ®µè§£é‡Šå…¶ä½œç”¨ä¸è®¾è®¡æ€è·¯ã€‚

---

## ğŸ§­ æ–‡ä»¶æ•´ä½“ç»“æ„æ¦‚è§ˆ

```yaml
defaults:
  - actor@actor_rollout_ref.actor: dp_actor
  ...
  - _self_
```

VERL ä½¿ç”¨ Hydra/OmegaConf çš„é…ç½®ç»§æ‰¿ç³»ç»Ÿï¼Œ`defaults` å—ç”¨æ¥å®šä¹‰é…ç½®ç»„åˆæ–¹å¼ï¼Œå³ï¼š

* æ¯ä¸€é¡¹ `<å­æ¨¡å—>@<è·¯å¾„>` è¡¨ç¤ºå°†ä¸€ä¸ª yaml æ–‡ä»¶ç»‘å®šåˆ°å½“å‰é…ç½®çš„å­æ¨¡å—ä¸Šï¼›
* `_self_` è¡¨ç¤ºå½“å‰è¿™ä¸ª `ppo_trainer.yaml` å¯ä»¥è¦†ç›–å‰é¢çš„é»˜è®¤è®¾ç½®ã€‚

---

## ğŸ§  æ ¸å¿ƒæ¨¡å—åˆ†è§£

---

### 1. `actor_rollout_ref`: Actorã€Rolloutã€Referenceæ¨¡å‹é…ç½®

è¿™ä¸ªæ¨¡å—ç»Ÿä¸€ç®¡ç†ï¼šactor æ¨¡å‹ï¼ˆè®­ç»ƒç”¨ï¼‰ã€rollout æ¨¡å‹ï¼ˆç”Ÿæˆç”¨ï¼‰ã€reference æ¨¡å‹ï¼ˆç”¨æ¥ç®—KLï¼‰ã€‚

```yaml
actor_rollout_ref:
  hybrid_engine: true  # ä½¿ç”¨æ··åˆå¼•æ“ï¼ˆactorã€rolloutã€refå…±å­˜ï¼‰
  model: {...}         # æ¨¡å‹åŠ è½½æ–¹å¼ã€LoRAã€æ˜¯å¦å¼€å¯ gradient checkpointing
  rollout: {...}       # rolloutä¸“ç”¨çš„ä¼˜åŒ–é…ç½®
  profiler: {...}      # profilerè®¾ç½®
```

ä¸»è¦å­—æ®µè§£æï¼š

#### `model.path`

æ¨¡å‹è·¯å¾„ï¼Œå¯ä»¥æ˜¯æœ¬åœ°æˆ–è¿œç¨‹ HuggingFace æ¨¡å‹ã€‚

#### `lora_rank`, `lora_alpha`, `target_modules`

LoRA çš„é…ç½®ï¼Œæ§åˆ¶æ˜¯å¦ä½ç§©å¾®è°ƒï¼Œå“ªäº›æ¨¡å—åº”ç”¨ LoRAã€‚

#### `enable_gradient_checkpointing`

èŠ‚çœå†…å­˜ï¼Œæé«˜ batch sizeï¼ˆä½†ä¼šå‡æ…¢è®­ç»ƒé€Ÿåº¦ï¼‰ã€‚

#### `rollout.enable_chunked_prefill`

æ˜¯å¦å¼€å¯ chunked prefillï¼ˆå¤§æ¨¡å‹æ—¶èƒ½æ˜¾è‘—æé«˜ååé‡ï¼‰ã€‚

---

### 2. `custom_reward_function`: è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°è®¾ç½®

```yaml
custom_reward_function:
  path: null
  name: compute_score
```

* `path`: å¯å¡«å…¥ä¸€ä¸ª Python æ–‡ä»¶è·¯å¾„ï¼Œè‡ªå®šä¹‰å¥–åŠ±å‡½æ•°ï¼›
* `name`: å¥–åŠ±å‡½æ•°åç§°ï¼Œé»˜è®¤ä½¿ç”¨ `compute_score`ã€‚

---

### 3. `algorithm`: PPOç®—æ³•çš„å…³é”®è¶…å‚æ•°é…ç½®

```yaml
algorithm:
  gamma: 1.0
  lam: 1.0
  adv_estimator: gae
  use_kl_in_reward: False
  kl_ctrl:
    type: fixed
    kl_coef: 0.001
```

è§£é‡Šå‡ ä¸ªå…³é”®å‚æ•°ï¼š

| å‚æ•°å                | è¯´æ˜                                                    |
| ------------------ | ----------------------------------------------------- |
| `gamma`            | æŠ˜æ‰£å› å­ï¼Œè¶Šä½è¶ŠçŸ­è§†ï¼›1.0 ä»£è¡¨ä¸æŠ˜æ‰£æœªæ¥å¥–åŠ±ã€‚                             |
| `lam`              | GAE (Generalized Advantage Estimator) çš„æƒè¡¡ç³»æ•°ã€‚          |
| `adv_estimator`    | ä¼˜åŠ¿å‡½æ•°ä¼°è®¡æ–¹å¼ï¼Œæ¯”å¦‚ `"gae"`ã€`"reinforce_plus_plus"` ç­‰ã€‚        |
| `use_kl_in_reward` | æ˜¯å¦å°†KLæ•£åº¦ä½œä¸ºå¥–åŠ±æƒ©ç½šé¡¹ã€‚                                       |
| `kl_ctrl`          | KLæ§åˆ¶ç­–ç•¥ï¼šå¯ä»¥æ˜¯ `fixed` æˆ– `adaptive`ï¼›adaptive å¯ç”¨äºåŠ¨æ€è°ƒèŠ‚KLç³»æ•°ã€‚ |

---

### 4. `trainer`: PPOä¸»è®­ç»ƒå™¨é…ç½®

```yaml
trainer:
  total_epochs: 30
  n_gpus_per_node: 8
  logger: ['console', 'wandb']
  project_name: verl_examples
  experiment_name: gsm8k
  resume_mode: auto
  val_before_train: True
  test_freq: -1
```

é‡ç‚¹å­—æ®µè¯´æ˜ï¼š

| å­—æ®µ                                        | å«ä¹‰                 |
| ----------------------------------------- | ------------------ |
| `total_epochs`                            | æ€»å…±è®­ç»ƒ epoch æ•°       |
| `save_freq`                               | å¤šä¹…ä¿å­˜ä¸€æ¬¡æ¨¡å‹ï¼ˆæŒ‰ stepï¼‰   |
| `logger`                                  | æ—¥å¿—è¾“å‡ºåç«¯ï¼Œå¦‚æ§åˆ¶å°æˆ– wandb |
| `rollout_data_dir`, `validation_data_dir` | rollout/valçš„ç”Ÿæˆè¾“å‡ºç›®å½• |
| `resume_mode`                             | è‡ªåŠ¨æ¢å¤è®­ç»ƒ             |
| `val_only` / `val_before_train`           | æ§åˆ¶éªŒè¯è¡Œä¸º             |

å…³äº **Nsight GPU profiling**ï¼š

```yaml
profile_steps: null
controller_nsight_options:
  trace: "cuda,nvtx,cublas,ucx"
  cuda-memory-usage: "true"
```

åªæœ‰åœ¨ `profile_steps` æŒ‡å®šæ—¶æ‰ä¼šç”Ÿæ•ˆï¼Œç”¨äº GPU æ€§èƒ½è¯Šæ–­åˆ†æã€‚

---

### 5. `ray_init`: Rayåˆ†å¸ƒå¼åˆå§‹åŒ–é…ç½®

```yaml
ray_init:
  num_cpus: null
  timeline_json_file: null
```

é€šå¸¸ç”¨äºåˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒï¼Œè‹¥ä½¿ç”¨ SLURM å»ºè®®æ˜¾å¼æŒ‡å®š `num_cpus`ã€‚

---

## ğŸ’¡ å®æˆ˜å»ºè®®

| éœ€æ±‚            | æ¨èè®¾ç½®                                       |
| ------------- | ------------------------------------------ |
| **èŠ‚çœæ˜¾å­˜**      | å¼€å¯ `enable_gradient_checkpointing: true`   |
| **è®­ç»ƒå¤šè½®å¯¹è¯ä»»åŠ¡**  | è®¾ç½® `use_kl_in_reward: true`ï¼Œå¼€å¯å‚è€ƒæ¨¡å‹KLæƒ©ç½š     |
| **è°ƒè¯•**        | åªå¯ç”¨ console æ—¥å¿— + è®¾ç½®è¾ƒå° batch                |
| **LoRAå¾®è°ƒ**    | è®¾ç½® `lora_rank > 0` å¹¶é…ç½®åˆé€‚çš„ `target_modules` |
| **Profiling** | å¼€å¯ `profile_steps` å¹¶é…ç½® `nsight_options`    |
