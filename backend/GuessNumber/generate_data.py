#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Desc: ç”ŸæˆåŒ…å« SFT + RL çš„è®­ç»ƒå’Œæµ‹è¯•é›†ï¼ˆjson + parquetï¼‰

import random
import json
import os
import pandas as pd
from copy import deepcopy
from sklearn.model_selection import train_test_split


def generate_guess_game_data(n=1000, num_range=(1, 100), max_turns=6):
    sft_data = []
    rl_data = []

    for _ in range(n):
        target = random.randint(*num_range)
        turns = []
        turns.append({
            "role": "system",
            "content": f"ä½ èƒ½å’Œç”¨æˆ·ä¸€èµ·ç©çŒœæ•°å­—ï¼Œå‡å¦‚ä½ ç°åœ¨å¿ƒé‡Œæƒ³çš„æ•°å­—æ˜¯{target}ï¼Œç”¨æˆ·è¯´ä»»æ„ä¸€ä¸ªæ•°å­—ï¼Œä½ åªä¼šè¯´å¤§äº†ï¼Œå°äº†ï¼Œæˆ–è€…ğŸ‰Bingoæ­£ç¡®"
        })

        low, high = num_range
        guessed_correctly = False
        assistant_responses = []

        for attempt in range(max_turns):
            guess = random.randint(low, high)
            turns.append({"role": "user", "content": str(guess)})
            if guess < target:
                response = "å°äº†"
                low = guess + 1
            elif guess > target:
                response = "å¤§äº†"
                high = guess - 1
            else:
                response = "ğŸ‰Bingoæ­£ç¡®"
                guessed_correctly = True

            turns.append({"role": "assistant", "content": response})
            assistant_responses.append(response)

            if guessed_correctly:
                break

        if not guessed_correctly:
            final_response = f"æ²¡çŒœä¸­å“¦ï¼Œæ­£ç¡®ç­”æ¡ˆæ˜¯ {target}"
            turns.append({"role": "assistant", "content": final_response})
            assistant_responses.append(final_response)

        # SFT æ ¼å¼ï¼šå…¨å¯¹è¯
        sft_data.append({"messages": deepcopy(turns)})

        # RL æ ¼å¼ï¼Œè¿™é‡Œä¸å¯¹å•Š
        rl_data.append({
            "prompt": deepcopy(turns),
            "data_source": "guess_number",
            "ability": "other",
            "reward_model": {
                "style": "rule",
                "ground_truth": str(target)
            },
            "extra_info": {
                "response": assistant_responses
            }
        })

    return sft_data, rl_data


def save_datasets(output_dir, sft_data, rl_data):
    os.makedirs(os.path.join(output_dir, "sft"), exist_ok=True)
    os.makedirs(os.path.join(output_dir, "rl"), exist_ok=True)

    # === ä¿å­˜ JSON åŸå§‹æ•°æ® ===
    with open(os.path.join(output_dir, "sft", "raw.json"), "w", encoding="utf-8") as f:
        json.dump(sft_data, f, ensure_ascii=False, indent=2)

    with open(os.path.join(output_dir, "rl", "raw.json"), "w", encoding="utf-8") as f:
        json.dump(rl_data, f, ensure_ascii=False, indent=2)

    # === åˆ‡åˆ† SFT æ•°æ® ===
    sft_train, sft_test = train_test_split(sft_data, test_size=0.1, random_state=42)
    sft_train_df = pd.DataFrame(sft_train)
    sft_test_df = pd.DataFrame(sft_test)
    sft_train_df.to_parquet(os.path.join(output_dir, "sft", "train.parquet"))
    sft_test_df.to_parquet(os.path.join(output_dir, "sft", "test.parquet"))

    # === åˆ‡åˆ† RL æ•°æ® ===
    rl_train, rl_test = train_test_split(rl_data, test_size=0.1, random_state=42)
    rl_train_df = pd.DataFrame(rl_train)
    rl_test_df = pd.DataFrame(rl_test)
    rl_train_df.to_parquet(os.path.join(output_dir, "rl", "train.parquet"))
    rl_test_df.to_parquet(os.path.join(output_dir, "rl", "test.parquet"))

    print(f"âœ… SFT train: {len(sft_train)}, test: {len(sft_test)}")
    print(f"âœ… RL  train: {len(rl_train)}, test: {len(rl_test)}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--num_samples", type=int, default=1000)
    parser.add_argument("--output_dir", type=str, default="./guess_number_dataset")
    args = parser.parse_args()

    sft_data, rl_data = generate_guess_game_data(n=args.num_samples)
    save_datasets(args.output_dir, sft_data, rl_data)
