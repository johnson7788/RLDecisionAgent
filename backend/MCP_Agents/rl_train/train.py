#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Date  : 2025/8/27
# @File  : train_query_agent.py
# @Author: johnson
# @Desc  : è®­ç»ƒä¸€ä¸ªâ€œæŸ¥è¯¢â€ReAct Agentï¼ˆART + LangGraphï¼ŒGRPOï¼‰ï¼Œä» questions.txt è¯»å–é—®é¢˜
#          å·¥å…·ï¼šæ£€ç´¢/è®¡ç®—ç­‰æ¥è‡ª MCP æœåŠ¡å™¨ï¼›return_final_answer_tool ä½¿ç”¨æœ¬åœ°å·¥å…·ä»¥ä¾¿è®­ç»ƒé˜¶æ®µè¯»å– final_answerã€‚

import logging
logging.basicConfig(level=logging.DEBUG)
import os
import json
import uuid
import time
import asyncio
import dotenv
import wandb
from dataclasses import dataclass
from textwrap import dedent
from typing import List, Dict, Any, Optional

import art
from art.langgraph import init_chat_model, wrap_rollout
from art.utils import iterate_dataset
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import Tool, tool
from pydantic import BaseModel, Field, ValidationError

from reward import search_reward, format_reward

# ==== MCP ====
# pip install fastmcp
from fastmcp import Client as MCPClient
from mcpserver.mcp_client import tool_definition_to_dict  #è‡ªå®šä¹‰MCPå·¥å…·

dotenv.load_dotenv()

# ---------------- è¿è¡Œé…ç½® ----------------
NAME = os.getenv("ART_NAME", "query-web")
MODEL_NAME = os.getenv("ART_MODEL", "Qwen/Qwen2.5-0.5B-Instruct")
PROJECT_NAME = os.getenv("ART_PROJECT", "content-training")
USE_LOCAL_BACKEND = os.getenv("ART_BACKEND", "local").lower() == "local"

WANDB_PROJECT = os.getenv("WANDB_PROJECT", PROJECT_NAME)
WANDB_ENTITY = os.getenv("WANDB_ENTITY")  # å¯ç©º
WANDB_RUN_NAME = os.getenv("WANDB_RUN_NAME", f"{NAME}-{time.strftime('%Y%m%d-%H%M%S')}")
MCP_CONFIG = os.getenv("MCP_CONFIG", "mcp_config.json")

print(f"{NAME} - {MODEL_NAME} - {PROJECT_NAME} - {os.getenv('WANDB_BASE_URL', '')}")
print(f"ä½¿ç”¨MCPçš„é…ç½®æ–‡ä»¶: {MCP_CONFIG}")

# ----------------- æ•°æ®ç»“æ„ -----------------
class FinalQAResult(BaseModel):
    task: List[Dict[str, Any]]                 # å•å…ƒç´ ä»»åŠ¡æ•°ç»„ï¼š[{"type":"qa","data":{"question":..., "text": ç­”æ¡ˆ}}]
    sources: List[str] = Field(default_factory=list)  # [1],[2]... å¯¹åº”çš„ URL åˆ—è¡¨

@dataclass
class QueryScenario:
    id: str
    prompt: str
    input_task: List[Dict[str, Any]]  # [{"type":"qa","data":{"question": "...", "text": ""}}]

class ProjectTrajectory(art.Trajectory):
    final: Optional[FinalQAResult] = None

# =========================
# MCP: å‘ç°ä¸è°ƒç”¨
# =========================

class MCPRegistry:
    """ä¿å­˜å·²å‘ç°çš„ MCP å·¥å…·ï¼ˆJSON Schemaï¼‰ä»¥åŠ åç§°â†’æœåŠ¡å™¨URL æ˜ å°„ã€‚"""
    def __init__(self):
        self.tools_schema: List[Dict[str, Any]] = []
        self.name_to_server: Dict[str, str] = {}

    def tools_schema_json(self) -> str:
        return json.dumps(self.tools_schema, ensure_ascii=False, indent=2)

    def find_server(self, tool_name: str) -> Optional[str]:
        return self.name_to_server.get(tool_name)

async def discover_mcp_tools(config_path: str) -> MCPRegistry:
    """ä» JSON é…ç½®è¯»å– MCP æœåŠ¡å™¨ï¼Œå¹¶æ±‡æ€»å·¥å…·å®šä¹‰ã€‚"""
    reg = MCPRegistry()
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            cfg = json.load(f)
    except FileNotFoundError:
        raise FileNotFoundError(f"MCPé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

    mcp_servers = (cfg or {}).get("mcpServers", {})
    if not mcp_servers:
        return reg

    for server_name, info in mcp_servers.items():
        if info.get("disabled"):
            continue
        url = info.get("url")
        if not url:
            continue
        try:
            client = MCPClient(url)
            async with client:
                tools = await client.list_tools()
        except Exception as e:
            print(f"âš ï¸  æ— æ³•ä» '{server_name}' ({url}) è·å–å·¥å…·: {e}")
            continue

        for t in tools:
            try:
                d = tool_definition_to_dict(t)  # {name, description, parameters}
            except Exception:
                d = {"name": getattr(t, "name", ""), "description": getattr(t, "description", None)}
            name = d.get("name")
            if not name:
                continue

            # è·³è¿‡ MCP ç«¯çš„ return_final_answer_toolï¼Œç¡®ä¿ä½¿ç”¨æœ¬åœ°ç‰ˆæœ¬
            if name == "return_final_answer_tool":
                print("â„¹ï¸  è·³è¿‡ MCP ç«¯ return_final_answer_toolï¼ˆä½¿ç”¨æœ¬åœ°å®ç°ç”¨äºè®­ç»ƒï¼‰ã€‚")
                continue

            if name in reg.name_to_server:
                print(f"âš ï¸  å·¥å…·åå†²çª: '{name}' åœ¨å¤šä¸ªæœåŠ¡å™¨ä¸­å‘ç°ï¼Œå°†ä½¿ç”¨å…ˆå‘ç°çš„æœåŠ¡å™¨ {reg.name_to_server[name]}")
            else:
                reg.name_to_server[name] = url

            if "parameters" not in d or d["parameters"] is None:
                d["parameters"] = {"type": "object", "properties": {}, "required": []}
            reg.tools_schema.append(d)

    print(f"ğŸ”§ é€šè¿‡ MCP å‘ç° {len(reg.tools_schema)} ä¸ªå·¥å…·ï¼ˆä¸å«æœ¬åœ° return_final_answer_toolï¼‰ã€‚")
    return reg

async def mcp_call_tool(server_url: str, tool_name: str, arguments: Dict[str, Any] | None) -> Any:
    """åœ¨æŒ‡å®š MCP æœåŠ¡å™¨ä¸Šè°ƒç”¨å·¥å…·ï¼Œå¹¶è¿”å› JSON å¯åºåˆ—åŒ–ç»“æœã€‚"""
    arguments = arguments or {}
    client = MCPClient(server_url)
    try:
        async with client:
            try:
                result = await client.call_tool(tool_name, arguments)
            except AttributeError:
                result = await client.call(tool_name, arguments)
    except Exception as e:
        return {"error": f"è°ƒç”¨å·¥å…·å¤±è´¥: {e}"}

    # å½’ä¸€åŒ–
    def _normalize(x: Any) -> Any:
        try:
            if hasattr(x, "model_dump"):
                x = x.model_dump()
        except Exception:
            pass
        try:
            json.dumps(x, ensure_ascii=False)
            return x
        except TypeError:
            return repr(x)

    return _normalize(result)

def _parse_json_obj_loose(s: Any) -> Optional[Dict[str, Any]]:
    """å®½æ¾è§£æï¼šè¾“å…¥å¯ä»¥æ˜¯ dict / JSON å­—ç¬¦ä¸² / ```json fencedã€‚"""
    if isinstance(s, dict):
        return s
    if not isinstance(s, str):
        return None
    t = s.strip()
    if t.startswith("```") and t.endswith("```"):
        inner = t.strip("`")
        # å»æ‰å¯èƒ½çš„è¯­è¨€æ ‡ç­¾
        for tag in ("json", "jsonc", "javascript", "js", "txt"):
            if inner.lower().startswith(tag):
                inner = inner[len(tag):].strip()
                break
        t = inner
    try:
        obj = json.loads(t)
        return obj if isinstance(obj, dict) else None
    except Exception:
        import re
        m = re.search(r"\{(?:.|\s)*\}", t)
        if m:
            try:
                obj = json.loads(m.group(0))
                return obj if isinstance(obj, dict) else None
            except Exception:
                return None
    return None

def _build_tool_description(defn: Dict[str, Any]) -> str:
    desc = (defn.get("description") or "").strip()
    schema = defn.get("parameters") or {}
    return dedent(f"""
    [MCP] {desc}
    å‚æ•° JSON Schemaï¼ˆä¾›å‚è€ƒï¼‰ï¼š
    {json.dumps(schema, ensure_ascii=False, indent=2)}
    """).strip()

def _make_langchain_tool_for_mcp(tool_name: str, server_url: str, defn: Dict[str, Any]) -> Tool:
    """æŠŠå•ä¸ª MCP å·¥å…·åŒ…è£…æˆ LangChain Toolï¼ˆä»…åšè½¬å‘ï¼Œä¸å«ä¸šåŠ¡é€»è¾‘ï¼‰ã€‚"""
    class _Args(BaseModel):
        input: str = Field(description="å‚æ•°å¯¹è±¡çš„ JSON å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ '{\"q\":\"åŒ—äº¬å¤©æ°”\"}'")

    async def _acoroutine(input: str) -> str:
        args = _parse_json_obj_loose(input) or {}
        res = await mcp_call_tool(server_url, tool_name, args)
        try:
            return json.dumps(res, ensure_ascii=False)
        except Exception:
            return str(res)

    return Tool(
        name=tool_name,
        description=_build_tool_description(defn),
        args_schema=_Args,
        coroutine=_acoroutine,
    )

# ----------------- ä»æ–‡ä»¶åŠ è½½é—®é¢˜ -----------------
def _default_questions_path() -> str:
    here = os.path.dirname(os.path.abspath(__file__))
    question_path = os.path.abspath(os.path.join(here, "..", "questions.txt"))
    return question_path

def load_questions(path: Optional[str] = None) -> List[str]:
    qpath = path or os.getenv("QUESTIONS_PATH") or _default_questions_path()
    print(f"å¼€å§‹åŠ è½½è®­ç»ƒé—®é¢˜ï¼š{qpath}")
    if not os.path.exists(qpath):
        raise FileNotFoundError(f"questions.txt æœªæ‰¾åˆ°ï¼š{qpath}")
    questions: List[str] = []
    with open(qpath, "r", encoding="utf-8") as f:
        for line in f:
            s = line.strip()
            if not s:
                continue
            if s.startswith("#"):
                continue
            questions.append(s)
    if not questions:
        raise ValueError("questions.txt ä¸ºç©ºæˆ–æ²¡æœ‰æœ‰æ•ˆé—®é¢˜è¡Œã€‚")
    return questions

# ----------------- rolloutï¼ˆæ ¸å¿ƒï¼‰ï¼šLangGraph + MCP å·¥å…· + æœ¬åœ° return_final_answer_tool -----------------
async def rollout(model: art.Model, scenario: QueryScenario) -> ProjectTrajectory:
    MAX_TURNS = 16
    traj = ProjectTrajectory(
        reward=0.0,
        messages_and_choices=[],
        metadata={"scenario_id": scenario.id}
    )

    # å‘ç° MCP å·¥å…·å¹¶æ³¨å†Œä¸º LangChain å·¥å…·ï¼ˆä¸åŒ…å« return_final_answer_toolï¼‰
    registry = await discover_mcp_tools(MCP_CONFIG)
    lc_tools: List[Tool] = []
    for defn in registry.tools_schema:
        name = defn.get("name")
        if not name:
            continue
        server_url = registry.find_server(name)
        if not server_url:
            continue
        lc_tools.append(_make_langchain_tool_for_mcp(name, server_url, defn))

    # æœ¬åœ°ï¼šreturn_final_answer_toolï¼ˆç”¨äºè®­ç»ƒé˜¶æ®µä¿å­˜æœ€ç»ˆ JSONï¼‰
    final: Optional[FinalQAResult] = None

    @tool
    def return_final_answer_tool(task: List[Dict[str, Any]], sources: List[str]) -> dict:
        """è¿”å›æœ€ç»ˆ JSONï¼šä¿æŒåŸæ ¼å¼çš„ task ä¸ sourcesã€‚"""
        nonlocal final
        try:
            final = FinalQAResult(task=task, sources=sources or [])
            return final.model_dump()
        except ValidationError as e:
            # è®© Agent æ”¶åˆ°é”™è¯¯å¹¶è‡ªæˆ‘ä¿®å¤
            return {"error": f"ValidationError: {str(e)}"}

    lc_tools.append(return_final_answer_tool)

    if not lc_tools:
        raise RuntimeError("æœªä» MCP å‘ç°ä»»ä½•å¯ç”¨å·¥å…·ï¼Œè¯·å…ˆå¯åŠ¨ MCP æœåŠ¡å™¨å¹¶æ£€æŸ¥é…ç½®ã€‚")

    # ====== æç¤ºè¯ï¼šæŸ¥è¯¢ Agent è¦æ±‚ ======
    tools_json = registry.tools_schema_json() + "\n(å¦å«æœ¬åœ°ï¼šreturn_final_answer_tool(task, sources))"
    system_prompt = dedent(f"""
    ä½ æ˜¯ä¸€ä¸ªæ•°æ®æŸ¥è¯¢ä¸åˆ†æåŠ©æ‰‹ï¼ˆQuery Agentï¼‰ã€‚ä½ çš„ä»»åŠ¡ï¼š
    1) è¯»å–ç”¨æˆ·æä¾›çš„å•å…ƒç´  JSON ä»»åŠ¡æ•°ç»„ï¼ˆtaskï¼‰ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ª {{type:"qa", data:{{question, text}}}}ï¼›
    2) å¿…è¦æ—¶è°ƒç”¨**å·²å‘ç°çš„ MCP å·¥å…·**è¿›è¡Œæ£€ç´¢/è®¡ç®—/è½¬æ¢ï¼›è¿™äº›å·¥å…·åœ¨æœ¬è®­ç»ƒä¸­ç»Ÿä¸€åªæœ‰ä¸€ä¸ªå‚æ•° inputï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼Œä½ éœ€è¦ä¼ å…¥å‚æ•°å¯¹è±¡çš„ JSON å­—ç¬¦ä¸²ï¼›
    3) è¾“å‡º 2~6 å¥ï¼ŒåŒ…å«å¯æ ¸éªŒäº‹å®ï¼ˆæ•°å­—/æ—¥æœŸ/æœºæ„/åœ°åç­‰ï¼‰ï¼Œå¹¶åœ¨å¥å°¾æ·»åŠ æ¥æºå¼•ç”¨ [n]ï¼ˆn ä» 1 å¼€å§‹ï¼Œå¯¹åº” sources ä¸­ URL çš„é¡ºåºï¼‰ï¼›
    4) ä¸å¾—ä¿®æ”¹è¾“å…¥ JSON çš„ç»“æ„å’Œå­—æ®µï¼Œåªèƒ½ç”¨æœ€ç»ˆç­”æ¡ˆè¦†ç›– data.textï¼›
    5) å®Œæˆå**å¿…é¡»è°ƒç”¨æœ¬åœ°çš„ `return_final_answer_tool(task, sources)`** è¿”å›æœ€ç»ˆ JSONï¼š
       - taskï¼šä¿æŒä¸è¾“å…¥ä¸€è‡´ï¼Œä»…æŠŠ data.text æ›¿æ¢ä¸ºä½ çš„ç­”æ¡ˆï¼ˆåŒ…å« [n] å¼•ç”¨ï¼‰ï¼›
       - sourcesï¼šå»é‡åçš„ URL åˆ—è¡¨ï¼Œé¡ºåºä¸ [n] å¯¹åº”ï¼›
    6) ä¸è¦åœ¨æ™®é€šå¯¹è¯ä¸­ç²˜è´´ JSONï¼ŒåŠ¡å¿…é€šè¿‡å·¥å…·è¿”å›æœ€ç»ˆ JSONã€‚

    ä¸‹é¢æ˜¯å·²å‘ç°çš„ MCP å·¥å…·ï¼ˆJSON Schemaï¼‰ï¼š\n{tools_json}
    """)

    chat_model = init_chat_model(MODEL_NAME, temperature=0.8)
    agent = create_react_agent(chat_model, tools=lc_tools)

    # ====== æ‰§è¡Œ Agent ======
    user_msg = dedent(f"""
    è¯·ä¸¥æ ¼æŒ‰ç³»ç»Ÿè¦æ±‚å¤„ç†ä»¥ä¸‹ JSON æŸ¥è¯¢ä»»åŠ¡ï¼ˆåªæ›¿æ¢ data.textï¼‰ï¼š
    {json.dumps(scenario.input_task, ensure_ascii=False)}
    """)

    await agent.ainvoke(
        {"messages": [SystemMessage(content=system_prompt),
                      HumanMessage(content=user_msg)]},
        config={"configurable": {"thread_id": str(uuid.uuid4())},
                "recursion_limit": MAX_TURNS},
    )

    # ====== è®¡ç®—å¥–åŠ± ======
    # æ”¶é›†å·¥å…·é˜¶æ®µè§è¿‡çš„ URLï¼Œç”¨äºä¸€è‡´æ€§æ ¡éªŒï¼ˆå¯¹æ‰€æœ‰å·¥å…·ç»“æœå°è¯•æŠ½å–ï¼‰
    tool_urls_seen: List[str] = []
    try:
        for m in traj.messages_and_choices:
            if m.get("role") != "tool":
                continue
            content = m.get("content")
            if isinstance(content, str):
                try:
                    content = json.loads(content)
                except Exception:
                    content = _parse_json_obj_loose(content)

            def _harvest(obj: Any):
                if isinstance(obj, list):
                    for it in obj:
                        if isinstance(it, dict) and isinstance(it.get("url"), str):
                            tool_urls_seen.append(it["url"])
                elif isinstance(obj, dict):
                    if isinstance(obj.get("url"), str):
                        tool_urls_seen.append(obj["url"])
                    for v in obj.values():
                        _harvest(v)
            _harvest(content)
    except Exception:
        pass

    if final:
        traj.final = final

        # ä»ç„¶æ²¿ç”¨åŸå¥–åŠ±ï¼šæ ¼å¼ + æœç´¢ä¸€è‡´æ€§
        fr = 0.0
        try:
            fr = format_reward(scenario.input_task, final.task)
        except Exception:
            fr = 0.0

        sr = 0.0
        try:
            sr = search_reward(final.task, final.sources, tool_urls_seen=tool_urls_seen)
        except Exception:
            sr = 0.0

        traj.reward = 0.5 * fr + 0.5 * sr
        traj.metrics["format_reward"] = fr
        traj.metrics["search_reward"] = sr
        traj.metrics["sources_count"] = len(set(final.sources))
    else:
        # æœªè¿”å›æœ€ç»ˆ JSONï¼Œç»™æœ€ä½å¥–åŠ±
        traj.reward = 0.0
        traj.metrics["format_reward"] = 0.0
        traj.metrics["search_reward"] = 0.0
        traj.metrics["sources_count"] = 0

    return traj

# ----------------- wandb è®°å½• -----------------
def _log_batch_to_wandb(*, batch, finished_groups):
    trajectories = []
    for g in finished_groups:
        if hasattr(g, "trajectories"):
            trajectories.extend(getattr(g, "trajectories"))
        else:
            try:
                trajectories.extend(list(g))
            except Exception:
                pass

    table = wandb.Table(columns=["scenario_id", "format_reward", "search_reward", "total_reward", "sources"])
    for t in trajectories[:50]:
        sid = (getattr(t, "metadata", {}) or {}).get("scenario_id", "")
        fr = (getattr(t, "metrics", {}) or {}).get("format_reward", 0.0)
        sr = (getattr(t, "metrics", {}) or {}).get("search_reward", 0.0)
        rw = getattr(t, "reward", 0.0)
        srcs = ", ".join(getattr(getattr(t, "final", None), "sources", []) or [])
        table.add_data(sid, fr, sr, rw, srcs)

    wandb.log({
        "train/step": batch.step,
        "train/epoch": batch.epoch,
        "samples/trajectories": table
    }, step=batch.step)

# ----------------- æ„é€ è®­ç»ƒé›† -----------------
def build_scenarios_from_questions(questions: List[str]) -> List[QueryScenario]:
    """
    æŠŠæ¯ä¸€æ¡é—®é¢˜è¡Œè½¬æ¢ä¸ºå•å…ƒç´  taskï¼š
    [{"type": "qa", "data": {"question": <q>, "text": ""}}]
    """
    scenarios: List[QueryScenario] = []
    for i, q in enumerate(questions, start=1):
        task = [{"type": "qa", "data": {"question": q, "text": ""}}]
        sid = f"q_{i}"
        prompt = "å›ç­” data.questionï¼ˆä»…å¡«å†™ data.textï¼ŒåŠ å…¥ [n] å¼•ç”¨å¹¶è¿”å› sourcesï¼‰ã€‚"
        scenarios.append(QueryScenario(id=sid, prompt=prompt, input_task=task))
    return scenarios

# ----------------- ä¸»è®­ç»ƒå¾ªç¯ -----------------
async def main():
    # wandb
    wandb.init(
        project=WANDB_PROJECT,
        entity=WANDB_ENTITY if WANDB_ENTITY else None,
        name=WANDB_RUN_NAME,
        config={
            "art_project": PROJECT_NAME,
            "art_name": NAME,
            "base_model": MODEL_NAME,
            "backend": "local" if USE_LOCAL_BACKEND else "skypilot",
        },
        settings=wandb.Settings(start_method="thread"),
    )
    wandb.define_metric("*", step_metric="train/step")

    # Backend
    if USE_LOCAL_BACKEND:
        from art.local.backend import LocalBackend
        backend = LocalBackend()
    else:
        from art.skypilot.backend import SkyPilotBackend
        backend = await SkyPilotBackend.initialize_cluster(
            cluster_name=os.getenv("ART_SKYPILOT_CLUSTER", "art-cluster"),
            gpu=os.getenv("ART_GPU", "A100"),
        )

    model = art.TrainableModel(name=NAME, project=PROJECT_NAME, base_model=MODEL_NAME)
    await model.register(backend)

    # ä» questions.txt åŠ è½½é—®é¢˜å¹¶æ„é€ åœºæ™¯
    questions = load_questions()
    scenarios = build_scenarios_from_questions(questions)

    training_config = {
        "groups_per_step": 2,
        "num_epochs": int(os.environ.get("NUM_EPOCHS", "2")),
        "rollouts_per_group": 3,
        "learning_rate": 1e-5,
        "max_steps": 6,
    }
    wandb.config.update(training_config)

    # æ•°æ®è¿­ä»£å™¨
    it = iterate_dataset(
        scenarios,
        groups_per_step=training_config["groups_per_step"],
        num_epochs=training_config["num_epochs"],
        initial_step=await model.get_step(),
    )

    for batch in it:
        print(f"[train] step={batch.step} epoch={batch.epoch}")

        # ç»„è£… TrajectoryGroupï¼šæ¯ä¸ªæ ·æœ¬ rollout å¤šæ¡è½¨è¿¹
        groups = []
        for s in batch.items:
            groups.append(
                art.TrajectoryGroup(
                    wrap_rollout(model, rollout)(model, s)
                    for _ in range(training_config["rollouts_per_group"])
                )
            )

        # æ”¶é›†è½¨è¿¹
        finished = await art.gather_trajectory_groups(
            groups, pbar_desc="gather",
            max_exceptions=training_config["rollouts_per_group"] * len(batch.items),
        )

        _log_batch_to_wandb(batch=batch, finished_groups=finished)

        # ç”¨æˆ‘ä»¬åœ¨ rollout é‡Œå†™å…¥çš„ reward åš GRPO
        await model.train(
            finished,
            config=art.TrainConfig(learning_rate=training_config["learning_rate"]),
        )

        if batch.step >= training_config["max_steps"]:
            break

    wandb.finish()

if __name__ == "__main__":
    asyncio.run(main())
