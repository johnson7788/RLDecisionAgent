# [run_qwen2-05b_sft.sh](run_qwen2-05b_sft.sh) è®²è§£

## ğŸš€ è„šæœ¬æ€»ä½“ä¸Šä¸‹æ–‡

è¯¥è„šæœ¬ä½¿ç”¨ Verl æ¡†æ¶æä¾›çš„ `verl.trainer.fsdp_sft_trainer` æ¨¡å—ï¼Œé€šè¿‡**PyTorch Fully Sharded Data Parallel (FSDP)** å®‰å…¨åˆ†å¸ƒå¼è®­ç»ƒï¼Œå®ç°å¯¹ Qwenâ€‘2.5â€‘0.5B æ¨¡å‹çš„å¤šè½®å¯¹è¯ SFT è®­ç»ƒï¼Œæ•°æ®æ¥æºäº ReToolâ€‘SFT çš„ parquet æ ¼å¼æ•°æ®é›†ï¼Œè¯¥æ¨¡å‹æ”¯æŒå·¥å…·è°ƒç”¨å’Œå¤šè½®äº¤äº’ã€‚Verl v0.4.x ç‰ˆæœ¬å·²æ­£å¼æ”¯æŒ Qwenâ€‘2.5Bã€qwen3 åŠ multiâ€‘turn SFT åŠŸèƒ½ ([data.safetycli.com][1])ã€‚

---

## ğŸ¯ è„šæœ¬åˆ†è§£ï¼šæ¯æ®µå‚æ•°å«ä¹‰

```bash
#!/bin/bash
set -x
# ä½¿ç”¨å“ªä¸ªæ˜¾å¡
export CUDA_VISIBLE_DEVICES=1,2

nnodes=1
nproc_per_node=2
```

* `CUDA_VISIBLE_DEVICES=1,2`: æŒ‡å®š GPU å¡ç¼–å·ä¸ºç¬¬ 1 å’Œç¬¬ 2 å¼ ã€‚
* `nnodes=1`ã€`nproc_per_node=2`: è¡¨ç¤ºå•èŠ‚ç‚¹è®­ç»ƒï¼Œæ¯èŠ‚ç‚¹å¯åŠ¨ 2 ä¸ªè¿›ç¨‹ï¼ˆ2 GPUsï¼‰ï¼Œä¸ä¸Šé¢çš„ `CUDA_VISIBLE_DEVICES` å¯¹åº”ã€‚

```bash
experiment_name=multiturn-sft-Qwen2.5-0.5B-Instruct
HDFS_ROOT=${HDFS_ROOT:-$PWD}
DATA_ROOT=${DATA_ROOT:-$PWD}
```

* `experiment_name`ï¼šæ­¤æ¬¡å®éªŒå‘½åï¼Œç”¨äºæ—¥å¿—/æ¨¡å‹æ–‡ä»¶ç»„ç»‡ã€‚
* `HDFS_ROOT` ä¸ `DATA_ROOT`ï¼šåˆ†åˆ«ç”¨äºæŒ‡å®šæ¨¡å‹å­˜å‚¨ã€æ•°æ®å­˜æ”¾çš„æ ¹è·¯å¾„ï¼Œè‹¥æœªè®¾ç½®åˆ™é»˜è®¤å½“å‰ç›®å½•ã€‚

```bash
TRAIN_DATA=.../trainâ€‘00000â€‘ofâ€‘00001.parquet
EVAL_DATA=åŒä¸Š
MODEL_PATH=$HDFS_ROOT/model/Qwen2.5-0.5B-Instruct
SAVE_PATH=$DATA_ROOT/checkpoint/$experiment_name
```

* æŒ‡å®šè®­ç»ƒä¸éªŒè¯æ•°æ®æ–‡ä»¶ï¼ˆParquet æ ¼å¼ï¼Œå¤šè½®æ¨¡å‹è¾“å…¥æ ¼å¼ï¼ŒåŒ…å« `messages` å’Œ `tools` å­—æ®µï¼‰ï¼›
* `model.partial_pretrain` æŒ‡å‘å·²æœ‰é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼›
* `SAVE_PATH` æ˜¯è®­ç»ƒ checkpoints çš„è¾“å‡ºç›®å½•ã€‚

```bash
torchrun --nnodes=$nnodes \
    --nproc_per_node=$nproc_per_node \
    -m verl.trainer.fsdp_sft_trainer \
    data.train_files=$TRAIN_DATA \
    data.val_files=$EVAL_DATA \
    data.max_length=16384 \
    data.train_batch_size=16 \
    data.multiturn.enable=true \
    data.multiturn.messages_key=messages \
    data.multiturn.tools_key=tools \
    data.micro_batch_size_per_gpu=2 \
    model.partial_pretrain=$MODEL_PATH \
    model.strategy=fsdp \
    trainer.default_local_dir=$SAVE_PATH \
    trainer.project_name=wuxibin-multiturn-sft \
    trainer.experiment_name=$experiment_name \
    trainer.logger='["console"]' \
    trainer.total_epochs=2 \
    ulysses_sequence_parallel_size=2 \
    use_remove_padding=true
```

### å‚æ•°åŠŸèƒ½æ€»ç»“ï¼š

#### **æ•°æ®é…ç½® (data.\*)**

* `data.train_files` & `data.val_files`: æŒ‡æ˜è®­ç»ƒå’ŒéªŒè¯æ•°æ®è·¯å¾„ï¼›
* `data.max_length=16384`: æ”¯æŒçš„æœ€å¤§ token é•¿åº¦ï¼Œé€‚ç”¨äºé•¿ä¸Šä¸‹æ–‡ï¼›
* `data.train_batch_size=16`: æ€» batch sizeï¼›
* `data.micro_batch_size_per_gpu=2`: æ¯ä¸ª GPU çš„å¾®æ‰¹é‡å¤§å°ï¼ˆ16 = 2 GPUs Ã— 2 micro-batch Ã— gradient accumulation stepsï¼‰ï¼›
* `data.multiturn.enable=true`: å¯ç”¨å¤šè½®å¯¹è¯å¾®è°ƒï¼›
* `messages_key=messages`, `tools_key=tools`: å¯¹åº”æ•°æ®é›†ä¸­ multiâ€‘turn è¾“å…¥é‡Œç”¨æˆ·/åŠ©æ‰‹å¯¹è¯å’Œå·¥å…·è°ƒç”¨å­—æ®µ ([Docfork][2], [Hugging Face][3], [verl.readthedocs.io][4])ã€‚

#### **æ¨¡å‹é…ç½®**

* `model.partial_pretrain=$MODEL_PATH`: æŒ‡å‘é¢„è®­ç»ƒæ¨¡å‹ checkpointï¼ŒSFT åœ¨æ­¤åŸºç¡€ä¸Š fine-tuneï¼›
* `model.strategy=fsdp`: ä½¿ç”¨ FSDP è®­ç»ƒç­–ç•¥ï¼ˆåˆ†å¸ƒå¼ shardï¼‰([GitHub][5], [data.safetycli.com][1])ã€‚

#### **è®­ç»ƒå™¨é…ç½® (trainer.\*)**

* `trainer.default_local_dir=$SAVE_PATH`: checkpoint/log ä¿å­˜è·¯å¾„ï¼›
* `trainer.project_name`, `trainer.experiment_name`: åˆ†åˆ«ç”¨äºæ—¥å¿—ç³»ç»Ÿï¼ˆå¦‚ wandbï¼‰æ ‡è¯†ï¼›
* `trainer.logger='["console"]'`: åªåœ¨æ§åˆ¶å°è¾“å‡ºæ—¥å¿—ï¼›
* `trainer.total_epochs=2`: å…±è®­ç»ƒ 2 ä¸ª epochã€‚

#### **æ€§èƒ½ä¸ parallelism**

* `ulysses_sequence_parallel_size=2`: å¯ç”¨ Ulysses sequence parallelismï¼Œæ”¯æŒé•¿ context åˆ†æ®µå¹¶è¡Œè®­ç»ƒï¼ˆQwenâ€‘ç³»åˆ—æ”¯æŒæ­¤æ–¹æ³•ï¼‰([data.safetycli.com][1], [Hugging Face][3], [GitHub][6])ã€‚
* `use_remove_padding=true`: å»é™¤ padding tokenï¼Œè¿›ä¸€æ­¥èŠ‚çº¦æ˜¾å­˜å¹¶åŠ é€Ÿè®¡ç®—ã€‚

---

## ğŸ” ä¸ºä»€ä¹ˆè¿™äº›è®¾ç½®ç»„åˆèµ·æ¥ï¼Ÿ

1. **FSDP + Ulysses sequence parallelism** è®©æ¨¡å‹åœ¨ GPU æ•°é‡æœ‰é™æ—¶ä¾ç„¶è®­ç»ƒé•¿ä¸Šä¸‹æ–‡å¯¹è¯æ¨¡å‹ã€‚
2. **Multi-turn æ•°æ®æ ¼å¼**ï¼šç®¡ç†å¯¹è¯å†å²å’Œå·¥å…·è°ƒç”¨ï¼Œç¬¦åˆ SGLang / ReTool çš„è®­ç»ƒéœ€æ±‚ï¼ˆåœ¨ Verl æ–°ç‰ˆæœ¬æ”¯æŒ multiâ€‘turn æ¨¡å‹è®­ç»ƒï¼‰([data.safetycli.com][1])ã€‚



---

## ğŸ§  æ€»ç»“

è¯¥è„šæœ¬æ˜¯ä¸€ä¸ªæ ‡å‡†çš„ä½¿ç”¨ Verl FSDP (v0.4.x) + dualâ€‘GPU + sequence parallelism + multiâ€‘turn æ•°æ®ç»“æ„è¿›è¡Œ SFT å¾®è°ƒçš„ç¤ºä¾‹ã€‚æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬ï¼š

* ä» Parquet æ ¼å¼çš„æ•°æ®é‡ŒåŠ è½½å¤šè½®å¯¹è¯æ ·æœ¬ï¼›
* æ”¯æŒå·¥å…·è°ƒç”¨ä¸Šä¸‹æ–‡ï¼ˆ`tools_key` å­—æ®µï¼‰ï¼›
* å€ŸåŠ© FSDP å’Œ Ulysses sequence parallelismï¼Œæœ‰æ•ˆå¤„ç†é•¿ä¸Šä¸‹æ–‡ä¸å¤§æ¨¡å‹ï¼›
* æ§åˆ¶ GPU æ‰€æœ‰å¯è§è®¾å¤‡ã€å¾®æ‰¹å¤§å°å’Œæ€» Epochï¼Œä½¿è®­ç»ƒèµ„æºå¯æ§ã€‚

å¦‚æœä½ è¿˜æƒ³è°ƒæ•´ä¾‹å¦‚ mixedâ€‘precisionã€wandb loggingã€æˆ–è€…è‡ªå®šä¹‰ prompt/response keyï¼ŒScé…ç½® yaml æ–‡ä»¶æˆ–è€…å‘½ä»¤è¡Œå‚æ•°å‡å¯è½»æ¾æ‰©å±• ([Hugging Face][7])ã€‚


# DAPOè®­ç»ƒè„šæœ¬ [run_qwen2-05b_dapo.sh](run_qwen2-05b_dapo.sh)
æˆ‘å¸®ä½ æ•´ä½“æ¢³ç†ä¸€ä¸‹è¿™ä¸ªè®­ç»ƒè„šæœ¬çš„é€»è¾‘ç»“æ„å’Œå‚æ•°ï¼Œæœ€åæŒ‡å‡ºå¯èƒ½å­˜åœ¨çš„é—®é¢˜æˆ–æ½œåœ¨é£é™©ã€‚

---

## è„šæœ¬ç»“æ„å’Œå‚æ•°è¯´æ˜

### 1. ç¯å¢ƒå˜é‡å’Œæ•°æ®è·¯å¾„

```bash
export CUDA_VISIBLE_DEVICES=1,2
```

æŒ‡å®šä½¿ç”¨ç¬¬2å’Œç¬¬3ä¸ªGPUï¼ˆä»0å¼€å§‹ç¼–å·ï¼‰ã€‚

```bash
HDFS_ROOT=${HDFS_ROOT:-$PWD}
DATA_ROOT=${DATA_ROOT:-$PWD}

dapo_math_17k=$DATA_ROOT/dataset/BytedTsinghua/train
aime_2024=$DATA_ROOT/dataset/Maxwell/validation
model_path=$HDFS_ROOT/checkpoint/multiturn-sft-Qwen2.5-0.5B-Instruct/global_step_250/huggingface

train_files="['$dapo_math_17k']"
test_files="['$aime_2024']"
```

* æ•°æ®å’Œæ¨¡å‹è·¯å¾„è®¾å®šï¼Œå¸¦é»˜è®¤å€¼ï¼ˆå½“å‰ç›®å½•ï¼‰ã€‚
* è®­ç»ƒé›†å’Œæµ‹è¯•é›†è·¯å¾„é€šè¿‡å­—ç¬¦ä¸²å½¢å¼ä¼ é€’ï¼Œæ³¨æ„æ˜¯ `train_files="['path']"`ï¼Œæ˜¯å­—ç¬¦ä¸²ï¼Œçœ‹è°ƒç”¨ç¨‹åºæ˜¯å¦èƒ½æ­£ç¡®è§£æã€‚

---

### 2. wandbå’Œå·¥å…·é…ç½®

```bash
tool_config_path=recipe/retool/sandbox_fusion_tool_config.yaml
project_name=wuxibin_retool
experiment_name=qwen2.5-05b_dapo
default_local_dir=$DATA_ROOT/checkpoint/$experiment_name
```

wandbé¡¹ç›®åå’Œå®éªŒåï¼Œæ—¥å¿—ä¿å­˜ç›®å½•ã€‚

---

### 3. ç®—æ³•ç›¸å…³å‚æ•°

```bash
adv_estimator=grpo

use_kl_in_reward=False
kl_coef=0.0
use_kl_loss=False
kl_loss_coef=0.0

clip_ratio_low=0.2
clip_ratio_high=0.28

max_turns=8
max_prompt_length=2048
max_response_length=16384
actor_lr=1e-6

n_resp_per_prompt=16
n_resp_per_prompt_val=30
```

* ç”¨äº† `grpo` ä½œä¸ºadvantageä¼°è®¡å™¨ã€‚
* KLç›¸å…³çš„æƒé‡éƒ½è®¾ç½®ä¸º0ï¼Œä¸”ä¸å¼€å¯KL losså’ŒKLå¥–åŠ±ã€‚
* å‰ªåˆ‡æ¯”ç‡èŒƒå›´å’Œå­¦ä¹ ç‡ç­‰ã€‚
* å¯¹è¯æœ€å¤§è½®æ•°8ï¼Œpromptå’Œresponseé•¿åº¦éƒ½æŒºå¤§ï¼ˆå°¤å…¶æ˜¯response 16384tokenï¼‰ã€‚
* ç”Ÿæˆå¤šä¸ªå“åº”æ•°é‡ã€‚

---

### 4. æ€§èƒ½ç›¸å…³

```bash
infer_tp=4 # vllm æ¨ç†tensor model parallel
train_sp=8 # è®­ç»ƒå¹¶è¡Œåº¦
offload=True

actor_max_token_len_per_gpu=$(( (max_prompt_length + max_response_length) * 1 ))
log_prob_max_token_len_per_gpu=$(( actor_max_token_len_per_gpu * 4 ))
```

* è®­ç»ƒä¸æ¨ç†çš„å¹¶è¡Œåº¦é…ç½®ã€‚
* offloadå¼€å…³ï¼Œå¯èƒ½æ§åˆ¶FSDPå‚æ•°å’Œä¼˜åŒ–å™¨offloadã€‚
* è®¡ç®—æœ€å¤§tokené•¿åº¦ï¼ˆæç¤º+å›å¤ï¼‰å’Œlog probæœ€å¤§tokené•¿åº¦ã€‚

---

### 5. æ‰§è¡Œpythonè®­ç»ƒæ¨¡å—ï¼Œå¹¶ä¼ é€’å¤§é‡å‚æ•°

è°ƒç”¨å‘½ä»¤éå¸¸é•¿ï¼Œä¸»è¦åŒ…æ‹¬ï¼š

* algorithmç›¸å…³å‚æ•°ï¼ˆadv\_estimatorï¼ŒKLç­‰ï¼‰
* dataç›¸å…³å‚æ•°ï¼ˆtrain/testæ–‡ä»¶ï¼Œbatch sizeï¼Œprompt/responseæœ€å¤§é•¿åº¦ï¼Œæ•°æ®è¿‡æ»¤å’Œæˆªæ–­æ–¹å¼ï¼Œè‡ªå®šä¹‰æ•°æ®é›†å’Œå¥–åŠ±å‡½æ•°ï¼‰
* actoræ¨¡å‹å’Œä¼˜åŒ–å‚æ•°ï¼ˆæ¨¡å‹è·¯å¾„ï¼Œclip ratioï¼Œå­¦ä¹ ç‡ï¼Œppo mini batchå¤§å°ï¼Œtokené•¿åº¦ï¼Œfsdp offloadç­‰ï¼‰
* rolloutç›¸å…³ï¼ˆvllmï¼Œå¼‚æ­¥æ¨¡å¼ï¼Œtensorå¹¶è¡Œï¼Œmulti-turnè®¾ç½®ï¼Œtool configï¼Œtop-pï¼Œæ¸©åº¦ï¼Œå“åº”æ•°ï¼‰
* trainerç›¸å…³ï¼ˆæ—¥å¿—ï¼ŒGPUæ•°é‡ï¼ŒéªŒè¯é¢‘ç‡ï¼Œå­˜å‚¨è·¯å¾„ï¼Œè®­ç»ƒepochæ•°ç­‰ï¼‰

---

## å¯èƒ½çš„é—®é¢˜å’Œå»ºè®®

1. **train\_files å’Œ test\_files æ ¼å¼**
   ä½ ä¼ çš„æ˜¯å­—ç¬¦ä¸²å½¢å¼çš„ `train_files="['$dapo_math_17k']"`ï¼Œå¦‚æœç¨‹åºé‡Œç›´æ¥ç”¨è¿™ä¸ªå­—ç¬¦ä¸²ï¼Œå¯èƒ½ä¼šè¯†åˆ«æˆä¸€ä¸ªå•å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯åˆ—è¡¨ã€‚
   **å»ºè®®ï¼š** ç¡®è®¤ `verl.trainer.main_ppo` çš„ä»£ç ä¸­å¯¹è¿™ç±»å‚æ•°çš„è§£æé€»è¾‘ï¼Œå¦‚æœæ˜¯ç”¨ `eval` æˆ– `json.loads`è§£æå­—ç¬¦ä¸²ä¸ºliståˆ™æ²¡é—®é¢˜ï¼Œå¦åˆ™å»ºè®®ä¼ æˆJSONæ ¼å¼æˆ–ç›´æ¥ä¸åŠ å¼•å·çš„åˆ—è¡¨æ ¼å¼ã€‚

2. **responseæœ€å¤§é•¿åº¦ 16384 tokenè¿‡å¤§**
   16k tokençš„å“åº”é•¿åº¦éå¸¸å¤§ï¼Œè®­ç»ƒå’Œæ¨ç†ä¼šéå¸¸æ¶ˆè€—æ˜¾å­˜ï¼Œä¸”å¯èƒ½å¯¼è‡´OOMæˆ–æ˜¾å­˜æº¢å‡ºã€‚ç¡®è®¤ä½ çš„GPUæ˜¾å­˜æ˜¯å¦è¶³å¤Ÿæ”¯æŒè¿™ä¸ªé•¿åº¦ã€‚
   **å»ºè®®ï¼š** å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œè€ƒè™‘ç¼©çŸ­max\_response\_lengthã€‚

3. **offloadè®¾ä¸ºTrue**
   ä½ ä½¿ç”¨äº†FSDPå‚æ•°å’Œä¼˜åŒ–å™¨å‚æ•°çš„offloadï¼Œç¡®ä¿ä½ çš„ç¡¬ä»¶å’Œä¾èµ–ç‰ˆæœ¬æ”¯æŒè¿™ä¸ªåŠŸèƒ½ï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚

4. **clip\_ratio\_low å’Œ clip\_ratio\_high è®¾ç½®**
   é€šå¸¸PPOçš„clip ratioè®¾ç½®åŒºé—´å¤§æ¦‚åœ¨0.1\~0.3ä¹‹é—´ï¼Œä½ è®¾ç½®çš„æ˜¯0.2åˆ°0.28ï¼ŒåŸºæœ¬åˆç†ï¼Œä½†æœ‰ç‚¹åçª„ã€‚clip\_ratio\_c=10.0æ¯”è¾ƒå¤§ï¼Œç¡®è®¤ä»£ç é‡Œclip\_ratio\_cçš„å«ä¹‰ã€‚

5. **`data.truncation='error'`**
   è¿™ä¸ªå‚æ•°å¾ˆå…³é”®ï¼Œè¡¨ç¤ºé‡åˆ°è¶…é•¿è¾“å…¥æ—¶æŠ›é”™ã€‚å¦‚æœä½ çš„æ•°æ®ä¸­æœ‰è¶…è¿‡max\_prompt\_lengthçš„è¾“å…¥ï¼Œä¼šå¯¼è‡´ç¨‹åºç›´æ¥æŠ¥é”™é€€å‡ºã€‚
   **å»ºè®®ï¼š** å¦‚æœæ•°æ®ä¸å¹²å‡€ï¼Œå»ºè®®æ”¹æˆ`truncate`æˆ–`ignore`ï¼Œæˆ–è€…ç¡®è®¤æ•°æ®æ¸…æ´—ã€‚

6. **n\_resp\_per\_prompt å’Œ n\_resp\_per\_prompt\_val**
   ç”Ÿæˆ16å’Œ30ä¸ªå“åº”ï¼Œå¯¹äºè®¡ç®—èµ„æºå’Œæ¨ç†æ—¶é—´è¦æ±‚æ¯”è¾ƒé«˜ï¼Œç¡®è®¤ä½ çš„è®­ç»ƒå’Œæ¨ç†ç¯å¢ƒæ”¯æŒã€‚

7. **`use_kl_loss=False`å’Œ`kl_loss_coef=0.0`ï¼Œ`use_kl_in_reward=False`ï¼Œ`kl_coef=0.0`**
   å¦‚æœä½ æœ¬æƒ³ç”¨KLæ¥æ§åˆ¶ç­–ç•¥åç¦»åŸºæ¨¡å‹ï¼Œç°åœ¨å…¨éƒ¨å…³é—­äº†ï¼Œç¡®è®¤æ˜¯å¦ç¬¦åˆä½ çš„è®­ç»ƒç›®æ ‡ã€‚

8. **è®­ç»ƒepochåªæœ‰1**
   `trainer.total_epochs=1`ï¼Œè¡¨ç¤ºåªè®­ç»ƒä¸€è½®ï¼Œæ˜¯å¦ç¬¦åˆé¢„æœŸï¼Ÿ

9. **CUDA\_VISIBLE\_DEVICES**
   è®¾ç½®ä¸º`1,2`ï¼Œä½†`trainer.n_gpus_per_node=2`ï¼Œç¬¦åˆè®¾ç½®ï¼Œä½†è¦ç¡®ä¿æœºå™¨ä¸Šç¬¬1å’Œç¬¬2å·GPUçŠ¶æ€è‰¯å¥½ã€‚


## SFTçš„æ¨¡å‹è¾“å‡ºç»“æœï¼Œ2å¼ æ˜¾å¡
```
ls -R checkpoint/multiturn-sft-Qwen2.5-0.5B-Instruct/global_step_250/
checkpoint/multiturn-sft-Qwen2.5-0.5B-Instruct/global_step_250/:
data.pt                             fsdp_config.json              model_world_size_2_rank_1.pt
extra_state_world_size_2_rank_0.pt  huggingface                   optim_world_size_2_rank_0.pt
extra_state_world_size_2_rank_1.pt  model_world_size_2_rank_0.pt  optim_world_size_2_rank_1.pt

checkpoint/multiturn-sft-Qwen2.5-0.5B-Instruct/global_step_250/huggingface:
added_tokens.json  config.json  generation_config.json  merges.txt  special_tokens_map.json  tokenizer.json  tokenizer_config.json  vocab.json

```